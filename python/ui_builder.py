"""
UI Builder - Gradio UI ìƒì„±
"""

import gradio as gr
import logging
from pathlib import Path
import config
from comfy_client import ComfyClient
from memory_manager import MemoryManager
from i18n import get_i18n, set_global_language, TRANSLATIONS

logger = logging.getLogger("UIBuilder")

# ì‹œë‚˜ë¦¬ì˜¤ ì´ë¯¸ì§€ ìºì‹œ (ì„±ëŠ¥ ìµœì í™”)
_scenario_image_cache = {}  # {scenario_name: (mtime, resized_image)}


class UIBuilder:
    """Gradio UI ë¹Œë”"""
    
    @staticmethod
    def create_ui(app_instance):
        """Gradio UI ìƒì„±"""
        # ì„¤ì • ë¡œë“œ
        saved_config = app_instance.load_config()
        env_config = app_instance.load_env_config()
        
        # ì–¸ì–´ ì„¤ì • ë¡œë“œ ë° ì „ì—­ ì„¤ì •
        language = env_config.get("language", "en")
        set_global_language(language)
        i18n = get_i18n()
        
        with gr.Blocks(title="Zeniji Emotion Simul") as demo:
            gr.Markdown("# ğŸ® Zeniji Emotion Simul")
            
            with gr.Tabs() as tabs:
                # ========== íƒ­ 1: ì´ˆê¸° ì„¤ì • ==========
                with gr.Tab(i18n.get_text("tab_setup"), id="setup_tab") as setup_tab:
                    gr.Markdown(f"## {i18n.get_text('setup_title')}")
                    
                    with gr.Row():
                        with gr.Column(scale=1):
                            gr.Markdown(f"### {i18n.get_text('player_settings')}")
                            player_name = gr.Textbox(
                                label=i18n.get_text("name"),
                                value=saved_config["player"].get("name", ""),
                                placeholder=i18n.get_text("name")
                            )
                            player_gender = gr.Radio(
                                label=i18n.get_text("gender"),
                                choices=[i18n.get_text("male"), i18n.get_text("female"), i18n.get_text("other")],
                                value=saved_config["player"].get("gender", i18n.get_default("player_gender"))
                            )
                        
                        with gr.Column(scale=1):
                            gr.Markdown(f"### {i18n.get_text('character_settings')}")
                            char_name = gr.Textbox(
                                label=i18n.get_text("name"),
                                value=saved_config["character"].get("name", i18n.get_default("character_name")),
                                placeholder=i18n.get_text("name")
                            )
                            # character ì •ë³´ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°
                            character_info = saved_config.get("character") or {}
                            char_age_val = character_info.get("age")
                            char_age_val = int(char_age_val) if char_age_val is not None else 21
                            
                            char_age = gr.Slider(
                                label=i18n.get_text("age"),
                                minimum=18,
                                maximum=100,
                                value=char_age_val,
                                step=1
                            )
                            char_gender = gr.Radio(
                                label=i18n.get_text("gender"),
                                choices=[i18n.get_text("male"), i18n.get_text("female"), i18n.get_text("other")],
                                value=saved_config["character"].get("gender", i18n.get_default("character_gender"))
                            )
                    
                    gr.Markdown(i18n.get_text("appearance_and_personality_section"))
                    appearance = gr.Textbox(
                        label=i18n.get_text("appearance"),
                        value=saved_config["character"].get("appearance", ""),
                        placeholder=i18n.get_text("appearance_placeholder"),
                        info=i18n.get_text("appearance_info"),
                        lines=3,
                        max_lines=5
                    )
                    personality = gr.Textbox(
                        label=i18n.get_text("personality"),
                        value=saved_config["character"].get("personality", ""),
                        placeholder=i18n.get_text("personality_placeholder"),
                        lines=3,
                        max_lines=5
                    )
                    speech_style = gr.Textbox(
                        label=i18n.get_text("character_speech_style_label"),
                        value=saved_config["character"].get("speech_style", i18n.get_default("character_speech_style")),
                        placeholder=i18n.get_text("character_speech_style_placeholder"),
                        info=i18n.get_text("character_speech_style_info"),
                        lines=2,
                        max_lines=4
                    )
                    
                    gr.Markdown(f"### {i18n.get_text('stats_title')}")
                    gr.Markdown(i18n.get_text("stats_info"))
                    
                    # initial_statsê°€ ì—†ê±°ë‚˜ Noneì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                    initial_stats = saved_config.get("initial_stats") or {}
                    
                    def safe_get_stat(key: str, default: float) -> float:
                        """ì•ˆì „í•˜ê²Œ í†µê³„ ê°’ ê°€ì ¸ì˜¤ê¸° (None ì²´í¬) - ëª…ì‹œì ìœ¼ë¡œ í•œ ë²ˆ ë” or ì²˜ë¦¬"""
                        val = initial_stats.get(key)
                        if val is None:
                            return default
                        try:
                            result = float(val)
                            # NaNì´ë‚˜ inf ì²´í¬
                            if not (0 <= result <= 100):
                                return default
                            return result
                        except (ValueError, TypeError):
                            return default
                    
                    with gr.Row():
                        with gr.Column():
                            # ëª…ì‹œì ìœ¼ë¡œ or ì²˜ë¦¬ë¡œ None ë°©ì§€
                            p_val = gr.Slider(
                                label=i18n.get_text("pleasure"),
                                minimum=0,
                                maximum=100,
                                value=safe_get_stat("P", 50.0) or 50.0,
                                step=1.0,
                                info=i18n.get_text("pleasure_info")
                            )
                            a_val = gr.Slider(
                                label=i18n.get_text("arousal"),
                                minimum=0,
                                maximum=100,
                                value=safe_get_stat("A", 40.0) or 40.0,
                                step=1.0,
                                info=i18n.get_text("arousal_info")
                            )
                            d_val = gr.Slider(
                                label=i18n.get_text("dominance"),
                                minimum=0,
                                maximum=100,
                                value=safe_get_stat("D", 40.0) or 40.0,
                                step=1.0,
                                info=i18n.get_text("dominance_info")
                            )
                        with gr.Column():
                            i_val = gr.Slider(
                                label=i18n.get_text("intimacy"),
                                minimum=0,
                                maximum=100,
                                value=safe_get_stat("I", 20.0) or 20.0,
                                step=1.0,
                                info=i18n.get_text("intimacy_info")
                            )
                            t_val = gr.Slider(
                                label=i18n.get_text("trust"),
                                minimum=0,
                                maximum=100,
                                value=safe_get_stat("T", 50.0) or 50.0,
                                step=1.0,
                                info=i18n.get_text("trust_info")
                            )
                            dep_val = gr.Slider(
                                label=i18n.get_text("dependency"),
                                minimum=0,
                                maximum=100,
                                value=safe_get_stat("Dep", 0.0) or 0.0,
                                step=1.0,
                                info=i18n.get_text("dependency_info")
                            )
                    
                    gr.Markdown(f"### {i18n.get_text('presets')}")
                    with gr.Row():
                        # preset ì´ë¦„ê³¼ i18n í‚¤ ë§¤í•‘ (í˜„ì¬ ì–¸ì–´ë§Œ í‘œì‹œ)
                        preset_i18n_keys = {
                            "ì†Œê¿‰ì¹œêµ¬": "preset_childhood_friend",
                            "í˜ê´€ ë¼ì´ë²Œ": "preset_hostile_rival",
                            "í”¼í/ì§‘ì°©": "preset_obsessive_depraved",
                        }
                        for preset_name in config.PRESETS.keys():
                            if preset_name in preset_i18n_keys:
                                i18n_key = preset_i18n_keys[preset_name]
                                display_name = i18n.get_text(i18n_key)
                            else:
                                display_name = preset_name
                            preset_btn = gr.Button(display_name, variant="secondary")
                            # lambda í´ë¡œì € ë¬¸ì œ í•´ê²° ë° fn ëª…ì‹œ
                            def make_preset_handler(name):
                                def handler():
                                    return app_instance.apply_preset(name)
                                return handler
                            preset_btn.click(
                                fn=make_preset_handler(preset_name),
                                inputs=[],
                                outputs=[p_val, a_val, d_val, i_val, t_val, dep_val, appearance, personality, speech_style]
                            )
                    
                    gr.Markdown(f"### {i18n.get_text('initial_situation')}")
                    initial_context = gr.Textbox(
                        label=i18n.get_text("initial_context"),
                        value=saved_config.get("initial_context", ""),
                        placeholder=i18n.get_text("initial_context_placeholder"),
                        lines=4,
                        max_lines=6
                    )
                    initial_background = gr.Textbox(
                        label=i18n.get_text("initial_background"),
                        value=saved_config.get("initial_background", i18n.get_text("initial_background_placeholder")),
                        placeholder=i18n.get_text("initial_background_placeholder"),
                        info=i18n.get_text("initial_background_info")
                    )
                    
                    # TODO: ëœë¤ ìƒí™© ìƒì„± ë²„íŠ¼
                    # random_context_btn = gr.Button("ğŸ² ëœë¤ ìƒí™© ìƒì„±", variant="secondary")
                    
                    setup_status = gr.Markdown("")
                    
                    # Character íŒŒì¼ ê´€ë¦¬
                    with gr.Row():
                        with gr.Column(scale=2):
                            character_file_dropdown = gr.Dropdown(
                                label=i18n.get_text("character_file"),
                                choices=app_instance.get_character_files(),
                                value=None,
                                info=i18n.get_text("character_file_info")
                            )
                        with gr.Column(scale=1):
                            character_filename_input = gr.Textbox(
                                label=i18n.get_text("save_filename"),
                                placeholder=i18n.get_text("save_filename_placeholder"),
                                info=i18n.get_text("save_filename_info")
                            )
                            overwrite_checkbox = gr.Checkbox(
                                label=i18n.get_text("overwrite_allow"),
                                value=False,
                                info=i18n.get_text("overwrite_info")
                            )
                    
                    with gr.Row():
                        load_btn = gr.Button(i18n.get_text("btn_load"), variant="secondary", size="lg")
                        save_btn = gr.Button(i18n.get_text("btn_save"), variant="secondary", size="lg")
                        start_btn = gr.Button(i18n.get_text("btn_start"), variant="primary", size="lg")
                        reload_character_btn = gr.Button(i18n.get_text("btn_reload"), variant="secondary", size="sm")
                    
                    def load_character(selected_file):
                        """ìºë¦­í„° íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°"""
                        if not selected_file:
                            return i18n.get_text("msg_file_not_selected"), *([gr.update()] * 16)
                        
                        try:
                            config = app_instance.load_character_config(selected_file)
                            
                            # UI ì—…ë°ì´íŠ¸
                            return (
                                i18n.get_text("msg_load_success", filename=selected_file),
                                config["player"].get("name", ""),
                                config["player"].get("gender", i18n.get_text("male")),
                                config["character"].get("name", "ì˜ˆë‚˜"),
                                config["character"].get("age", 21),
                                config["character"].get("gender", i18n.get_text("female")),
                                config["character"].get("appearance", ""),
                                config["character"].get("personality", ""),
                                config["character"].get("speech_style", i18n.get_default("character_speech_style")),
                                config["initial_stats"].get("P", 50.0),
                                config["initial_stats"].get("A", 40.0),
                                config["initial_stats"].get("D", 40.0),
                                config["initial_stats"].get("I", 20.0),
                                config["initial_stats"].get("T", 50.0),
                                config["initial_stats"].get("Dep", 0.0),
                                config.get("initial_context", ""),
                                config.get("initial_background", i18n.get_text("initial_background_placeholder"))
                            )
                        except Exception as e:
                            logger.error(f"Failed to load character: {e}")
                            return i18n.get_text("msg_load_failed", error=str(e)), *([gr.update()] * 16)
                    
                    def save_character(filename, overwrite, player_name, player_gender, char_name, char_age, char_gender,
                                     appearance, personality, speech_style, p_val, a_val, d_val, i_val, t_val, dep_val,
                                     initial_context, initial_background):
                        """ìºë¦­í„° ì„¤ì • ì €ì¥"""
                        if not filename or not filename.strip():
                            return i18n.get_text("msg_filename_required"), gr.Dropdown()
                        
                        try:
                            # íŒŒì¼ëª… ì •ë¦¬
                            clean_filename = filename.strip()
                            if not clean_filename.endswith('.json'):
                                clean_filename = f"{clean_filename}.json"
                            
                            # íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                            file_path = config.CHARACTER_DIR / clean_filename
                            if file_path.exists() and not overwrite:
                                return i18n.get_text("msg_file_exists", filename=clean_filename), gr.Dropdown()
                            
                            # ì„¤ì • ë°ì´í„° êµ¬ì„±
                            config_data = {
                                "player": {
                                    "name": player_name or "",
                                    "gender": player_gender or i18n.get_text("male")
                                },
                                "character": {
                                    "name": char_name or "ì˜ˆë‚˜",
                                    "age": int(char_age) if char_age else 21,
                                    "gender": char_gender or i18n.get_text("female"),
                                    "appearance": appearance or "",
                                "personality": personality or "",
                                "speech_style": speech_style or i18n.get_default("character_speech_style")
                                },
                                "initial_stats": {
                                    "P": float(p_val) if p_val is not None else 50.0,
                                    "A": float(a_val) if a_val is not None else 40.0,
                                    "D": float(d_val) if d_val is not None else 40.0,
                                    "I": float(i_val) if i_val is not None else 20.0,
                                    "T": float(t_val) if t_val is not None else 50.0,
                                    "Dep": float(dep_val) if dep_val is not None else 0.0
                                },
                                "initial_context": initial_context or "",
                                "initial_background": initial_background or i18n.get_text("initial_background_placeholder")
                            }
                            
                            if app_instance.save_character_config(config_data, clean_filename):
                                # character_config.jsonë„ ë®ì–´ì“°ê¸° (ë‹¤ìŒ ì‹¤í–‰ ì‹œ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©)
                                app_instance.save_config(config_data)
                                
                                # ë“œë¡­ë‹¤ìš´ ëª©ë¡ ìƒˆë¡œê³ ì¹¨
                                updated_files = app_instance.get_character_files()
                                return i18n.get_text("msg_save_success", filename=clean_filename), gr.Dropdown(choices=updated_files, value=clean_filename.replace('.json', ''))
                            else:
                                return i18n.get_text("msg_save_failed"), gr.Dropdown()
                        except Exception as e:
                            logger.error(f"Failed to save character: {e}")
                            return i18n.get_text("msg_save_failed"), gr.Dropdown()
                    
                    def reload_character_files():
                        """ìºë¦­í„° íŒŒì¼ ëª©ë¡ ìƒˆë¡œê³ ì¹¨"""
                        updated_files = app_instance.get_character_files()
                        return gr.Dropdown(choices=updated_files)
                    
                    load_btn.click(
                        load_character,
                        inputs=[character_file_dropdown],
                        outputs=[
                            setup_status,
                            player_name, player_gender,
                            char_name, char_age, char_gender,
                            appearance, personality, speech_style,
                            p_val, a_val, d_val, i_val, t_val, dep_val,
                            initial_context, initial_background
                        ]
                    )
                    
                    save_btn.click(
                        save_character,
                        inputs=[
                            character_filename_input,
                            overwrite_checkbox,
                            player_name, player_gender,
                            char_name, char_age, char_gender,
                            appearance, personality, speech_style,
                            p_val, a_val, d_val, i_val, t_val, dep_val,
                            initial_context, initial_background
                        ],
                        outputs=[setup_status, character_file_dropdown]
                    )
                    
                    reload_character_btn.click(
                        reload_character_files,
                        outputs=[character_file_dropdown]
                    )
                    
                    def normalize_chatbot_history(history):
                        """Chatbot íˆìŠ¤í† ë¦¬ë¥¼ Gradio 6.x ë”•ì…”ë„ˆë¦¬ í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”"""
                        if history is None:
                            return []
                        
                        normalized = []
                        for item in history:
                            if isinstance(item, list) and len(item) == 2:
                                # íŠœí”Œ í˜•ì‹ [user_msg, assistant_msg]ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                                user_msg = item[0] if item[0] else ""
                                assistant_msg = item[1] if item[1] else ""
                                
                                # ë¬¸ìì—´ë¡œ ë³€í™˜ (ë¦¬ìŠ¤íŠ¸ë‚˜ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ì²˜ë¦¬)
                                if isinstance(user_msg, list):
                                    user_msg = ''.join([part.get('text', '') if isinstance(part, dict) else str(part) for part in user_msg])
                                elif isinstance(user_msg, dict):
                                    user_msg = user_msg.get('content', str(user_msg))
                                else:
                                    user_msg = str(user_msg) if user_msg else ""
                                
                                if isinstance(assistant_msg, list):
                                    assistant_msg = ''.join([part.get('text', '') if isinstance(part, dict) else str(part) for part in assistant_msg])
                                elif isinstance(assistant_msg, dict):
                                    assistant_msg = assistant_msg.get('content', str(assistant_msg))
                                else:
                                    assistant_msg = str(assistant_msg) if assistant_msg else ""
                                
                                # ë”•ì…”ë„ˆë¦¬ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                                if user_msg:
                                    normalized.append({"role": "user", "content": user_msg})
                                if assistant_msg:
                                    normalized.append({"role": "assistant", "content": assistant_msg})
                            elif isinstance(item, dict):
                                # ì´ë¯¸ ë”•ì…”ë„ˆë¦¬ í˜•ì‹ì¸ ê²½ìš°
                                role = item.get("role", "")
                                content = item.get("content", "")
                                
                                # contentê°€ ë¦¬ìŠ¤íŠ¸ë‚˜ ë‹¤ë¥¸ í˜•ì‹ì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
                                if isinstance(content, list):
                                    content = ''.join([part.get('text', '') if isinstance(part, dict) else str(part) for part in content])
                                else:
                                    content = str(content) if content else ""
                                
                                # roleê³¼ contentê°€ ëª¨ë‘ ìˆì–´ì•¼ í•¨
                                if role and content:
                                    normalized.append({"role": role, "content": content})
                            else:
                                # ì•Œ ìˆ˜ ì—†ëŠ” í˜•ì‹ì€ ê±´ë„ˆë›°ê¸°
                                logger.warning(f"Unknown history item format: {type(item)}, skipping")
                        
                        return normalized
                    
                    def continue_chat(selected_scenario):
                        """ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë¶ˆëŸ¬ì™€ì„œ ëŒ€í™” ì´ì–´ê°€ê¸°"""
                        if not selected_scenario:
                            return "âš ï¸ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.", gr.Tabs(selected=None), [], "", "", None, "", "", "", None
                        
                        try:
                            # ì‹œë‚˜ë¦¬ì˜¤ ë¶ˆëŸ¬ì˜¤ê¸°
                            scenario_data = app_instance.load_scenario(selected_scenario)
                            
                            if not scenario_data:
                                return f"âš ï¸ ì‹œë‚˜ë¦¬ì˜¤ '{selected_scenario}'ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", gr.Tabs(selected=None), [], "", "", None, "", "", "", None
                            
                            # conversation í•„ë“œ í™•ì¸ (ì „ì²´ ëŒ€í™”)
                            # ê¸°ì¡´ ì‹œë‚˜ë¦¬ì˜¤ í˜¸í™˜: conversationì´ ì—†ìœ¼ë©´ context.recent_turnsì—ì„œ ë³µì›
                            if "conversation" in scenario_data:
                                history = scenario_data["conversation"]
                            elif "context" in scenario_data:
                                # context.recent_turnsì—ì„œ conversation í˜•ì‹ìœ¼ë¡œ ë³µì›
                                context = scenario_data["context"]
                                recent_turns = context.get("recent_turns", [])
                                if not recent_turns:
                                    return f"âš ï¸ ì‹œë‚˜ë¦¬ì˜¤ '{selected_scenario}'ì— ëŒ€í™” ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.", gr.Tabs(selected=None), [], "", "", None, "", "", "", None
                                
                                # recent_turnsì—ì„œ conversation í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                                history = []
                                for turn_data in recent_turns:
                                    player_input = turn_data.get("player_input", "")
                                    character_speech = turn_data.get("character_speech", "")
                                    if player_input:
                                        history.append({"role": "user", "content": player_input})
                                    if character_speech:
                                        history.append({"role": "assistant", "content": character_speech})
                                
                                # í˜¸í™˜ì„±ì„ ìœ„í•´ scenario_dataì— conversation í•„ë“œ ì¶”ê°€
                                scenario_data["conversation"] = history
                            else:
                                return f"âš ï¸ ì‹œë‚˜ë¦¬ì˜¤ '{selected_scenario}'ì— ëŒ€í™” ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤. (conversation ë˜ëŠ” context í•„ë“œ ì—†ìŒ)", gr.Tabs(selected=None), [], "", "", None, "", "", "", None
                            
                            if not history:
                                return f"âš ï¸ ì‹œë‚˜ë¦¬ì˜¤ '{selected_scenario}'ì— ëŒ€í™” ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.", gr.Tabs(selected=None), [], "", "", None, "", "", "", None
                            
                            # context í™•ì¸ (ìµœê·¼ 10í„´)
                            context = scenario_data.get("context", {})
                            recent_turns = context.get("recent_turns", [])
                            
                            # ì‹œë‚˜ë¦¬ì˜¤ì™€ ê°™ì€ ì´ë¦„ì˜ ì´ë¯¸ì§€ íŒŒì¼ë„ ë¶ˆëŸ¬ì˜¤ê¸°
                            scenario_image_path = config.SCENARIOS_DIR / f"{selected_scenario}.png"
                            if scenario_image_path.exists():
                                try:
                                    from PIL import Image
                                    app_instance.current_image = Image.open(scenario_image_path)
                                    logger.info(f"Scenario image loaded from: {scenario_image_path}")
                                except Exception as e:
                                    logger.warning(f"Failed to load scenario image: {e}")
                                    app_instance.current_image = None
                            else:
                                app_instance.current_image = None
                                logger.debug(f"Scenario image not found: {scenario_image_path} (optional)")
                            
                            # ëª¨ë¸ì´ ë¡œë“œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                            if not app_instance.model_loaded:
                                status_msg, success = app_instance.load_model()
                                if not success:
                                    return f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {status_msg}", gr.Tabs(selected=None), [], "", "", None, "", "", "", None
                            
                            # ì´ˆê¸° ì„¤ì • ì •ë³´ ë³µì› (í”„ë¡¬í”„íŠ¸ì— í•„ìˆ˜)
                            if app_instance.brain is not None and "initial_config" in scenario_data:
                                app_instance.brain.set_initial_config(scenario_data["initial_config"])
                                logger.info("Initial config restored")
                            
                            # ìƒíƒœ ì •ë³´ ë³µì›
                            if app_instance.brain is not None and "state" in scenario_data:
                                state_data = scenario_data["state"]
                                state = app_instance.brain.state
                                
                                # Stats ë³µì›
                                if "stats" in state_data:
                                    stats = state_data["stats"]
                                    state.P = stats.get("P", state.P)
                                    state.A = stats.get("A", state.A)
                                    state.D = stats.get("D", state.D)
                                    state.I = stats.get("I", state.I)
                                    state.T = stats.get("T", state.T)
                                    state.Dep = stats.get("Dep", state.Dep)
                                
                                # ê´€ê³„ ìƒíƒœ ë³µì›
                                if "relationship" in state_data:
                                    state.relationship_status = state_data["relationship"]
                                    # previous_relationshipë„ ì´ˆê¸°í™” (ë‹¤ìŒ í„´ì—ì„œ ë³€ê²½ ê°ì§€ìš©)
                                    app_instance.previous_relationship = state_data["relationship"]
                                    logger.info(f"Relationship status restored: {state.relationship_status}")
                                
                                # ê¸°ë¶„ì€ interpret_moodë¡œ ê³„ì‚°ë˜ë¯€ë¡œ ë³µì› ë¶ˆí•„ìš” (stats ë³µì› í›„ ìë™ ê³„ì‚°ë¨)
                                # moodëŠ” ì €ì¥ë§Œ í•˜ê³  ë³µì›ì€ í•˜ì§€ ì•ŠìŒ (ê³„ì‚°ëœ ê°’ì´ë¯€ë¡œ)
                                
                                # ë±ƒì§€ ë³µì›
                                if "badges" in state_data:
                                    state.badges = set(state_data["badges"])
                                
                                # íŠ¸ë¼ìš°ë§ˆ ë ˆë²¨ ë³µì›
                                if "trauma_level" in state_data:
                                    state.trauma_level = state_data["trauma_level"]
                                
                                # í˜„ì¬ ë°°ê²½ ë³µì›
                                if "current_background" in state_data:
                                    state.current_background = state_data["current_background"]
                                
                                # ì´ í„´ ìˆ˜ ë³µì›
                                if "total_turns" in state_data:
                                    state.total_turns = state_data["total_turns"]
                                
                                # ì¥ê¸° ê¸°ì–µ ë³µì›
                                if "long_memory" in state_data:
                                    state.long_memory = state_data["long_memory"]
                                    logger.info(f"ì¥ê¸° ê¸°ì–µ ë³µì›ë¨ (ê¸¸ì´: {len(state.long_memory)}): {state.long_memory[:100]}...")
                                else:
                                    logger.warning("ì‹œë‚˜ë¦¬ì˜¤ì— ì¥ê¸° ê¸°ì–µ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                                
                                # moodëŠ” interpret_moodë¡œ ê³„ì‚°ë˜ëŠ” ê°’
                                from logic_engine import interpret_mood
                                calculated_mood = interpret_mood(state)
                                
                                logger.info(f"State restored: relationship={state.relationship_status}, mood={calculated_mood}, badges={list(state.badges)}, background={state.current_background}, turns={state.total_turns}, long_memory exists: {bool(state.long_memory)}")
                                
                                # ì´ì „ ë±ƒì§€ ëª©ë¡ë„ ë³µì› (ì•Œë¦¼ìš©)
                                if isinstance(state.badges, list):
                                    app_instance.previous_badges = set(state.badges)
                                elif isinstance(state.badges, set):
                                    app_instance.previous_badges = state.badges.copy()
                                else:
                                    app_instance.previous_badges = set()
                            
                            # ë¬¸ë§¥ ì •ë³´ ë³µì› (recent_turnsê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ conversationì—ì„œ ì¶”ë¡ )
                            if app_instance.brain is not None and hasattr(app_instance.brain, 'history'):
                                if recent_turns:
                                    # DialogueHistoryì— í„´ ì¶”ê°€
                                    for turn_data in recent_turns:
                                        from state_manager import DialogueTurn
                                        character_speech = turn_data.get("character_speech", "")
                                        turn = DialogueTurn(
                                            turn_number=turn_data.get("turn_number", 0),
                                            player_input=turn_data.get("player_input", ""),
                                            character_speech=character_speech,
                                            character_thought=turn_data.get("character_thought", ""),
                                            emotion=turn_data.get("emotion", "neutral"),
                                            visual_prompt=turn_data.get("visual_prompt", ""),
                                            background=turn_data.get("background", "")
                                        )
                                        app_instance.brain.history.add(turn)
                                    logger.info(f"Context restored: {len(recent_turns)} turns")
                                else:
                                    # recent_turnsê°€ ì—†ìœ¼ë©´ conversationì—ì„œ ì¶”ë¡  (í•˜ìœ„ í˜¸í™˜ì„±)
                                    logger.warning("recent_turnsê°€ ì—†ì–´ conversationì—ì„œ ë³µì› ì‹œë„")
                                
                                # ë§ˆì§€ë§‰ ëŒ€í™”ì˜ backgroundë¥¼ current_backgroundì— ë°˜ì˜
                                if "last_background" in context and context["last_background"]:
                                    state.current_background = context["last_background"]
                                    logger.info(f"Last background restored to current_background: {context['last_background']}")
                                elif recent_turns and len(recent_turns) > 0:
                                    last_turn_bg = recent_turns[-1].get("background", "")
                                    if last_turn_bg:
                                        state.current_background = last_turn_bg
                                        logger.info(f"Last turn background restored to current_background: {last_turn_bg}")
                            
                            # conversationì—ì„œ chatbot íˆìŠ¤í† ë¦¬ ìƒì„± (ì •ê·œí™” í•¨ìˆ˜ ì‚¬ìš©)
                            chatbot_history = normalize_chatbot_history(history)
                            
                            # í˜„ì¬ ìƒíƒœë¡œ ì°¨íŠ¸ ìƒì„±
                            if app_instance.brain is not None:
                                stats = app_instance.brain.state.get_stats_dict()
                                current_chart = app_instance.create_radar_chart(stats, {})
                                app_instance.current_chart = current_chart
                            else:
                                current_chart = app_instance.current_chart
                            
                            # í˜„ì¬ ì´ë¯¸ì§€ì™€ ì°¨íŠ¸ëŠ” ìœ ì§€
                            current_image = app_instance.current_image
                            
                            # stats_text ìƒì„±
                            if app_instance.brain is not None:
                                state = app_instance.brain.state
                                stats = state.get_stats_dict()
                                
                                # moodëŠ” interpret_moodë¡œ ê³„ì‚°ë˜ëŠ” ê°’
                                from logic_engine import interpret_mood
                                calculated_mood = interpret_mood(state)
                                
                                stats_axis_title = i18n.get_text("stats_axis_title", category="ui")
                                stats_change_title = i18n.get_text("stats_change_title", category="ui")
                                relationship_label = i18n.get_text("relationship_label", category="ui")
                                mood_label = i18n.get_text("mood_label", category="ui")
                                badge_label = i18n.get_text("badge_label", category="ui")
                                badge_none = i18n.get_text("badge_none", category="ui")
                                p_label = i18n.get_text("stat_p_short", category="ui")
                                a_label = i18n.get_text("stat_a_short", category="ui")
                                d_label = i18n.get_text("stat_d_short", category="ui")
                                i_label = i18n.get_text("stat_i_short", category="ui")
                                t_label = i18n.get_text("stat_t_short", category="ui")
                                dep_label = i18n.get_text("stat_dep_short", category="ui")

                                stats_text = f"""
<div style="font-size: 0.85em; color: #666;">
<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 10px;">
<div>
<strong>{stats_axis_title}:</strong><br>
{p_label}: {stats.get('P', 0):.0f}<br>
{a_label}: {stats.get('A', 0):.0f}<br>
{d_label}: {stats.get('D', 0):.0f}<br>
</div>
<div>
<strong>{stats_change_title}:</strong><br>
{i_label}: {stats.get('I', 0):.0f}<br>
{t_label}: {stats.get('T', 0):.0f}<br>
{dep_label}: {stats.get('Dep', 0):.0f}<br>
</div>
</div>
<br>
<strong>{relationship_label}:</strong> {state.relationship_status} | <strong>{mood_label}:</strong> {calculated_mood}<br>
<strong>{badge_label}:</strong> {', '.join(state.badges) or badge_none}
</div>
"""
                            else:
                                stats_text = ""
                            
                            return (
                                f"âœ… ì‹œë‚˜ë¦¬ì˜¤ '{selected_scenario}' ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!",
                                gr.Tabs(selected="chat_tab"),
                                chatbot_history,
                                "",
                                stats_text,
                                current_image,
                                "",
                                "",
                                "",
                                current_chart
                            )
                        except Exception as e:
                            logger.error(f"Failed to continue chat: {e}")
                            import traceback
                            logger.error(traceback.format_exc())
                            return f"âŒ ì‹œë‚˜ë¦¬ì˜¤ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}", gr.Tabs(selected=None), [], "", "", None, "", "", "", None
                
                # ========== íƒ­ 2: ì‹œë‚˜ë¦¬ì˜¤ ==========
                with gr.Tab(i18n.get_text("tab_scenario"), id="scenario_tab") as scenario_tab:
                    gr.Markdown(f"## {i18n.get_text('scenario_title')}")
                    
                    # í”Œë ˆì´ìŠ¤í™€ë” ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜ (4:3 ë¹„ìœ¨, ë†’ì´ê°€ ë” ë†’ê²Œ)
                    def create_placeholder_image():
                        """ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš° ì‚¬ìš©í•  í”Œë ˆì´ìŠ¤í™€ë” ìƒì„± (4:3 ë¹„ìœ¨)"""
                        from PIL import Image, ImageDraw, ImageFont
                        card_width = 200
                        card_height = int(card_width * 4 / 3)  # 4:3 ë¹„ìœ¨ (267)
                        placeholder = Image.new('RGB', (card_width, card_height), color='#e0e0e0')
                        draw = ImageDraw.Draw(placeholder)
                        try:
                            font = ImageFont.truetype("malgun.ttf", 16)
                        except:
                            try:
                                font = ImageFont.truetype("gulim.ttc", 16)
                            except:
                                font = ImageFont.load_default()
                        text = i18n.get_text("no_image")
                        bbox = draw.textbbox((0, 0), text, font=font)
                        text_width = bbox[2] - bbox[0]
                        text_height = bbox[3] - bbox[1]
                        position = ((card_width - text_width) // 2, (card_height - text_height) // 2)
                        draw.text(position, text, fill='#999999', font=font)
                        return placeholder
                    
                    placeholder_img = create_placeholder_image()
                    
                    def get_scenario_gallery_items():
                        """ì‹œë‚˜ë¦¬ì˜¤ ê°¤ëŸ¬ë¦¬ ì•„ì´í…œ ìƒì„± (ë™ì  ì—…ë°ì´íŠ¸ ê°€ëŠ¥, ìºì‹± ì ìš©)"""
                        from PIL import Image
                        import os
                        global _scenario_image_cache
                        
                        scenarios = app_instance.get_scenario_files()
                        
                        # íŒŒì¼ ìˆ˜ì • ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ìµœì‹ ìˆœ ì •ë ¬ (ì—­ìˆœ)
                        scenario_paths = []
                        for scenario_name in scenarios:
                            scenario_path = config.SCENARIOS_DIR / f"{scenario_name}.json"
                            if scenario_path.exists():
                                mtime = os.path.getmtime(scenario_path)
                                scenario_paths.append((mtime, scenario_name))
                        
                        # ìˆ˜ì • ì‹œê°„ ì—­ìˆœ ì •ë ¬ (ìµœì‹ ì´ ë¨¼ì €)
                        scenario_paths.sort(reverse=True)
                        scenarios = [name for _, name in scenario_paths]
                        
                        gallery_items = []
                        
                        # 4:3 ë¹„ìœ¨ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (ë†’ì´ê°€ ë” ë†’ê²Œ)
                        target_width = 200
                        target_height = int(target_width * 4 / 3)  # 267
                        
                        # í”Œë ˆì´ìŠ¤í™€ë”ëŠ” ì´ë¯¸ ì˜¬ë°”ë¥¸ í¬ê¸°ë¡œ ìƒì„±ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ìºì‹±ë§Œ ìˆ˜í–‰
                        if 'placeholder' not in _scenario_image_cache:
                            _scenario_image_cache['placeholder'] = (0, placeholder_img)
                        
                        for scenario_name in scenarios:  # ì „ì²´ ì‹œë‚˜ë¦¬ì˜¤ í‘œì‹œ
                            image_path = config.SCENARIOS_DIR / f"{scenario_name}.png"
                            
                            # ìºì‹œ í™•ì¸
                            cache_key = scenario_name
                            use_cache = False
                            resized_img = None
                            
                            if image_path.exists():
                                try:
                                    # ì´ë¯¸ì§€ íŒŒì¼ì˜ ìˆ˜ì • ì‹œê°„ í™•ì¸
                                    img_mtime = os.path.getmtime(image_path)
                                    
                                    # ìºì‹œì— ìˆê³  ìˆ˜ì • ì‹œê°„ì´ ê°™ìœ¼ë©´ ìºì‹œ ì‚¬ìš©
                                    if cache_key in _scenario_image_cache:
                                        cached_mtime, cached_img = _scenario_image_cache[cache_key]
                                        if cached_mtime == img_mtime:
                                            resized_img = cached_img
                                            use_cache = True
                                    
                                    # ìºì‹œ ë¯¸ìŠ¤ ë˜ëŠ” íŒŒì¼ì´ ë³€ê²½ëœ ê²½ìš° ìƒˆë¡œ ë¡œë“œ ë° ë¦¬ì‚¬ì´ì¦ˆ
                                    if not use_cache:
                                        img = Image.open(image_path)
                                        resized_img = img.resize((target_width, target_height), Image.Resampling.LANCZOS)
                                        # ìºì‹œì— ì €ì¥
                                        _scenario_image_cache[cache_key] = (img_mtime, resized_img)
                                    
                                    gallery_items.append((resized_img, scenario_name))
                                except Exception as e:
                                    logger.warning(f"Failed to load/resize image for {scenario_name}: {e}")
                                    # ì‹¤íŒ¨ ì‹œ í”Œë ˆì´ìŠ¤í™€ë” ì‚¬ìš©
                                    placeholder_resized = _scenario_image_cache['placeholder'][1]
                                    gallery_items.append((placeholder_resized, scenario_name))
                            else:
                                # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ í”Œë ˆì´ìŠ¤í™€ë” ì‚¬ìš©
                                placeholder_resized = _scenario_image_cache['placeholder'][1]
                                gallery_items.append((placeholder_resized, scenario_name))
                        
                        # ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ìºì‹œ í•­ëª© ì •ë¦¬ (í˜„ì¬ ì‹œë‚˜ë¦¬ì˜¤ ëª©ë¡ì— ì—†ëŠ” ê²ƒë“¤)
                        current_scenarios = set(scenarios)
                        keys_to_remove = [key for key in _scenario_image_cache.keys() 
                                        if key != 'placeholder' and key not in current_scenarios]
                        for key in keys_to_remove:
                            del _scenario_image_cache[key]
                        
                        return gallery_items
                    
                    # ì‹œë‚˜ë¦¬ì˜¤ ê°¤ëŸ¬ë¦¬ (ë™ì  ì—…ë°ì´íŠ¸ ê°€ëŠ¥)
                    scenario_gallery = gr.Gallery(
                        label=i18n.get_text("scenario_title"),
                        value=get_scenario_gallery_items(),
                        show_label=False,
                        elem_id="scenario-gallery",
                        columns=4,
                        height="auto",
                        allow_preview=False
                    )
                    
                    # CSSë¡œ ì´ë¯¸ì§€ í¬ê¸°(ì¹´ë“œ í­)ì— ë§ì¶° ë™ì ìœ¼ë¡œ ì¡°ì ˆ
                    gr.HTML(value="""
                    <style>
                    /* ì‹œë‚˜ë¦¬ì˜¤ ê°¤ëŸ¬ë¦¬ ì´ë¯¸ì§€: ì¹´ë“œ í­ì— ë§ì¶° ë°˜ì‘í˜•ìœ¼ë¡œ ì¶•ì†Œ/í™•ëŒ€ (3:4 ë¹„ìœ¨ ìœ ì§€) */
                    #scenario-gallery img {
                        width: 100% !important;
                        height: auto !important;
                        max-width: 200px !important;  /* ì¹´ë“œê°€ 1ê°œì¼ ë•Œë„ ì¼ì • í¬ê¸° ì´ìƒ ì»¤ì§€ì§€ ì•Šë„ë¡ ì œí•œ */
                        aspect-ratio: 3 / 4 !important;  /* ê¸°ì¡´ 200x267 ë¹„ìœ¨ ìœ ì§€ (ì„¸ë¡œí˜•) */
                        object-fit: contain !important;
                    }
                    /* ê°¤ëŸ¬ë¦¬ ì•„ì´í…œ ì»¨í…Œì´ë„ˆ - ì¤‘ì•™ ì •ë ¬, ìµœëŒ€ ë„ˆë¹„ ì œí•œ (ì¹´ë“œê°€ ì ì„ ë•Œë„ ì¼ì • í¬ê¸° ìœ ì§€) */
                    #scenario-gallery .gallery-item {
                        display: flex !important;
                        flex-direction: column !important;
                        align-items: center !important;
                        justify-content: flex-start !important;
                        box-sizing: border-box !important;
                        max-width: 200px !important;  /* ì¹´ë“œê°€ 1ê°œì¼ ë•Œë„ 4ê°œ ìˆì„ ë•Œì™€ ê°™ì€ í¬ê¸°ë¡œ ì œí•œ */
                        width: 100% !important;  /* ê·¸ë¦¬ë“œ ë‚´ì—ì„œ ë°˜ì‘í˜•ìœ¼ë¡œ ì¡°ì •ë˜ë˜, max-widthë¡œ ì œí•œ */
                    }
                    /* ì œëª©/ìº¡ì…˜ ìŠ¤íƒ€ì¼ - ê°€ìš´ë° ì •ë ¬ ë° 2ì¤„ê¹Œì§€ í‘œì‹œ */
                    #scenario-gallery .gallery-item .caption-label {
                        max-width: 180px !important;
                        width: 180px !important;
                        margin-left: auto !important;
                        margin-right: auto !important;
                        margin-top: 4px !important;
                        margin-bottom: 0 !important;
                        padding: 0 !important;
                        white-space: normal !important;
                        word-wrap: break-word !important;
                        overflow-wrap: break-word !important;
                        display: -webkit-box !important;
                        -webkit-line-clamp: 2 !important;
                        -webkit-box-orient: vertical !important;
                        overflow: hidden !important;
                        text-overflow: ellipsis !important;
                        line-height: 1.4em !important;
                        max-height: 2.8em !important;
                        text-align: center !important;
                        box-sizing: border-box !important;
                    }
                    </style>
                    """)
                    
                    # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
                    with gr.Row():
                        reload_scenario_cards_btn = gr.Button(i18n.get_text("btn_reload"), variant="secondary")
                    
                    def reload_scenario_gallery():
                        """ì‹œë‚˜ë¦¬ì˜¤ ê°¤ëŸ¬ë¦¬ ìƒˆë¡œê³ ì¹¨"""
                        return gr.Gallery(value=get_scenario_gallery_items())
                    
                    reload_scenario_cards_btn.click(
                        fn=reload_scenario_gallery,
                        outputs=[scenario_gallery]
                    )
                    
                    # ì¹´ë“œ í´ë¦­ ì´ë²¤íŠ¸ëŠ” ëŒ€í™” íƒ­ ì»´í¬ë„ŒíŠ¸ê°€ ì •ì˜ëœ í›„ì— ì—°ê²°ë¨ (ì•„ë˜ì—ì„œ ì²˜ë¦¬)
                
                # ========== íƒ­ 3: ëŒ€í™” ==========
                with gr.Tab(i18n.get_text("tab_chat"), id="chat_tab") as chat_tab:
                    # ì´ë²¤íŠ¸ ì•Œë¦¼ (ê³ ì • ìœ„ì¹˜, í•„ìš”ì‹œ í‘œì‹œ)
                    event_notification = gr.HTML(value="", visible=False, elem_id="event-notification-container")
                    
                    with gr.Row():
                        with gr.Column(scale=2):
                            chatbot = gr.Chatbot(label=i18n.get_text("chat_label"), height=500)
                            
                            # ì†ë§ˆìŒ: Accordionìœ¼ë¡œ ì ‘ê¸°/í¼ì¹˜ê¸° ê°€ëŠ¥í•˜ê²Œ
                            with gr.Accordion(i18n.get_text("thought_title"), open=False, visible=True) as thought_accordion:
                                thought_display = gr.Markdown(label="", visible=True)
                            
                            action_display = gr.Markdown(label=i18n.get_text("action_title"), visible=True)
                            user_input = gr.Textbox(label=i18n.get_text("input_label"), placeholder=i18n.get_text("input_placeholder"), interactive=False)
                            submit_btn = gr.Button(i18n.get_text("btn_send"), variant="primary", interactive=False)
                        
                        with gr.Column(scale=1):
                            stats_chart = gr.Plot(label=i18n.get_text("stats_chart_label"), show_label=True)
                            stats_display = gr.Markdown(label=i18n.get_text("stats_detail_label"), show_label=True)
                            # ì´ë¯¸ì§€ì™€ ì¬ì‹œë„/ì €ì¥ ë²„íŠ¼ì„ í•¨ê»˜ í‘œì‹œí•˜ê¸° ìœ„í•œ ì»¨í…Œì´ë„ˆ
                            image_display = gr.Image(label=i18n.get_text("character_image_label"), height=400, show_label=False)
                            retry_image_btn = gr.Button(i18n.get_text("btn_retry_image"), variant="secondary", size="sm", visible=False)
                            save_image_btn = gr.Button(i18n.get_text("btn_save_image"), variant="secondary", size="sm", visible=True)
                            save_moment_btn = gr.Button(i18n.get_text("btn_save_moment"), variant="secondary", size="sm", visible=True)
                            # ë²„íŠ¼ ìƒíƒœ/ë©”ì‹œì§€ í‘œì‹œìš©
                            retry_image_status = gr.Markdown("", visible=False, elem_id="retry-status")
                            save_image_status = gr.Markdown("", visible=False, elem_id="save-image-status")
                            save_moment_status = gr.Markdown("", visible=False, elem_id="save-moment-status")
                    
                    # ì‹œë‚˜ë¦¬ì˜¤ ì €ì¥ (ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì•„ë˜, í™”ë©´ ë„ˆë¹„ ì „ì²´ ì‚¬ìš©)
                    with gr.Row():
                        scenario_save_name = gr.Textbox(
                            label=i18n.get_text("scenario_save_label"),
                            placeholder=i18n.get_text("scenario_save_placeholder"),
                            info=i18n.get_text("scenario_save_info"),
                            scale=3
                        )
                        save_scenario_btn = gr.Button(i18n.get_text("btn_save_scenario"), variant="secondary", scale=1)
                        scenario_save_status = gr.Markdown("")
                    
                    # ì´ë¯¸ì§€ ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±°ìš© hidden state
                    image_update_trigger = gr.State(value=None)
                    
                    def on_submit(message, history):
                        """ë©”ì¸ ëŒ€í™” ì²˜ë¦¬ í•¸ë“¤ëŸ¬ (ë¡œë”© ì´ìŠˆ ë””ë²„ê¹…ìš© ë¡œê·¸/ì˜ˆì™¸ ë°©ì–´ í¬í•¨)"""
                        try:
                            logger.info(f"[on_submit] called. model_loaded={app_instance.model_loaded}, "
                                        f"message_preview={str(message)[:50]!r}, "
                                        f"history_type={type(history).__name__}")
                            
                            if not app_instance.model_loaded:
                                logger.info("[on_submit] model not loaded yet, returning history only.")
                                # historyë¥¼ ì•ˆì „í•˜ê²Œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                                if history is None:
                                    history = []
                                elif isinstance(history, set):
                                    history = list(history)
                                elif not isinstance(history, list):
                                    try:
                                        history = list(history)
                                    except (TypeError, ValueError):
                                        history = []
                                normalized_history = normalize_chatbot_history(history)
                                return normalized_history, "", "", "", "", None, None, gr.HTML(value="", visible=False)  # ë§ˆì§€ë§‰ì€ event_notification
                            
                            # ì´ì „ ì°¨íŠ¸ë¥¼ ë¨¼ì € ë°˜í™˜ (ë¡œë”© ì¤‘ì—ë„ ì°¨íŠ¸ê°€ ë³´ì´ë„ë¡)
                            # ì´ˆê¸° ì°¨íŠ¸ê°€ ì—†ìœ¼ë©´ ìƒì„±
                            if app_instance.current_chart is None and app_instance.brain is not None:
                                logger.debug("[on_submit] current_chart is None, creating initial chart.")
                                stats = app_instance.brain.state.get_stats_dict()
                                app_instance.current_chart = app_instance.create_radar_chart(stats, {})
                            previous_chart = app_instance.current_chart if app_instance.current_chart is not None else None
                            
                            # historyë¥¼ ì•ˆì „í•˜ê²Œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ ë° ì •ê·œí™”
                            if history is None:
                                history = []
                            elif isinstance(history, set):
                                history = list(history)
                            elif not isinstance(history, list):
                                try:
                                    history = list(history)
                                except (TypeError, ValueError):
                                    history = []
                            
                            # íˆìŠ¤í† ë¦¬ ì •ê·œí™”
                            normalized_history = normalize_chatbot_history(history)
                            logger.debug(f"[on_submit] normalized_history_len={len(normalized_history)}")
                            
                            new_history, output, stats, image, choices, thought, action, chart, event_notification = app_instance.process_turn(message, normalized_history)
                            
                            # ë°˜í™˜ ì „ì— íˆìŠ¤í† ë¦¬ ë‹¤ì‹œ ì •ê·œí™” (ì•ˆì „ì¥ì¹˜)
                            normalized_new_history = normalize_chatbot_history(new_history)
                            
                            # imageê°€ ìƒˆë¡œ ìƒì„±ëìœ¼ë©´ triggerì— ë„£ê³ , ì•„ë‹ˆë©´ None
                            # ì°¨íŠ¸ëŠ” ì´ì „ ì°¨íŠ¸ë¥¼ ë¨¼ì € ë°˜í™˜í•˜ê³ , ìƒˆ ì°¨íŠ¸ëŠ” ë‚˜ì¤‘ì— ì—…ë°ì´íŠ¸
                            # ì´ë²¤íŠ¸ ì•Œë¦¼ì´ ìˆìœ¼ë©´ í‘œì‹œ, ì—†ìœ¼ë©´ ìˆ¨ê¹€ (ë¹ˆ ë¬¸ìì—´ë¡œ ì´ˆê¸°í™”)
                            event_visible = bool(event_notification and event_notification.strip())
                            event_html = event_notification if event_visible else ""
                            
                            logger.info(f"[on_submit] completed. "
                                        f"stats_keys={list(stats.keys()) if isinstance(stats, dict) else 'N/A'}, "
                                        f"image_generated={image is not None}, "
                                        f"event_visible={event_visible}")
                            
                            return (
                                normalized_new_history,
                                "",
                                stats,
                                thought,
                                action,
                                image,
                                previous_chart if previous_chart else chart,
                                gr.HTML(value=event_html, visible=event_visible),
                            )
                        except Exception as e:
                            import traceback
                            logger.error(f"[on_submit] ERROR: {e}")
                            logger.error(traceback.format_exc())
                            # ì˜ˆì™¸ê°€ ë°œìƒí•˜ë”ë¼ë„ Gradio ì²´ì¸ì´ ëë‚˜ë„ë¡ ì•ˆì „í•œ ê¸°ë³¸ê°’ ë°˜í™˜
                            safe_history = normalize_chatbot_history(history or [])
                            error_html = gr.HTML(
                                value=f"<div style='color:red;font-size:0.85em;'>âš ï¸ on_submit ì˜¤ë¥˜: {str(e)}</div>",
                                visible=True,
                            )
                            return safe_history, "", "", "", "", None, None, error_html
                    
                    def update_chart_async(history):
                        """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì°¨íŠ¸ ì—…ë°ì´íŠ¸ (ë¡œë”© ì´ìŠˆ ë””ë²„ê¹…ìš© ë¡œê·¸ í¬í•¨)"""
                        try:
                            logger.debug(f"[update_chart_async] called. model_loaded={app_instance.model_loaded}, "
                                         f"history_type={type(history).__name__}")
                            if not app_instance.model_loaded or not history:
                                logger.debug("[update_chart_async] skipped (model not loaded or empty history).")
                                return gr.skip()
                            
                            # ë§ˆì§€ë§‰ ëŒ€í™”ì—ì„œ stats ì¶”ì¶œí•˜ì—¬ ì°¨íŠ¸ ìƒì„±
                            # ì‹¤ì œë¡œëŠ” process_turnì—ì„œ ì´ë¯¸ ì°¨íŠ¸ë¥¼ ìƒì„±í–ˆìœ¼ë¯€ë¡œ current_chart ì‚¬ìš©
                            if app_instance.current_chart is not None:
                                logger.debug("[update_chart_async] returning current_chart.")
                                return app_instance.current_chart
                        except Exception as e:
                            import traceback
                            logger.error(f"[update_chart_async] ERROR: {e}")
                            logger.error(traceback.format_exc())
                        logger.debug("[update_chart_async] no chart to update, skip.")
                        return gr.skip()
                    
                    def save_scenario_handler(scenario_name, history):
                        """ì‹œë‚˜ë¦¬ì˜¤ ì €ì¥ í•¸ë“¤ëŸ¬ (Gradio historyì—ì„œ ì „ì²´ ëŒ€í™” ì €ì¥, context.recent_turnsëŠ” ìµœê·¼ 10í„´ë§Œ ì €ì¥)"""
                        if not scenario_name or not scenario_name.strip():
                            return i18n.get_text("msg_scenario_save_name_required")
                        
                        try:
                            logger.info(f"Saving scenario: {scenario_name}")
                            
                            # Brainì—ì„œ ìƒíƒœ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                            scenario_data = {}
                            
                            if app_instance.brain is not None:
                                # í˜„ì¬ ìƒíƒœ ì •ë³´
                                state = app_instance.brain.state
                                
                                # moodëŠ” interpret_mood í•¨ìˆ˜ë¡œ ê³„ì‚°ë˜ëŠ” ê°’
                                from logic_engine import interpret_mood
                                calculated_mood = interpret_mood(state)
                                
                                scenario_data["state"] = {
                                    "stats": {
                                        "P": state.P,
                                        "A": state.A,
                                        "D": state.D,
                                        "I": state.I,
                                        "T": state.T,
                                        "Dep": state.Dep
                                    },
                                    "relationship": state.relationship_status,
                                    "mood": calculated_mood,  # ê³„ì‚°ëœ mood ê°’ ì €ì¥
                                    "badges": list(state.badges) if hasattr(state, 'badges') else [],
                                    "trauma_level": state.trauma_level if hasattr(state, 'trauma_level') else 0.0,
                                    "current_background": state.current_background if hasattr(state, 'current_background') else "",
                                    "total_turns": state.total_turns if hasattr(state, 'total_turns') else 0,
                                    "long_memory": state.long_memory if hasattr(state, 'long_memory') else ""  # ì¥ê¸° ê¸°ì–µ ì €ì¥
                                }
                                
                                # ì´ˆê¸° ì„¤ì • ì •ë³´ (í”„ë¡¬í”„íŠ¸ì— í•„ìˆ˜)
                                if hasattr(app_instance.brain, 'initial_config') and app_instance.brain.initial_config:
                                    scenario_data["initial_config"] = app_instance.brain.initial_config
                                
                                # ì „ì²´ ëŒ€í™”ë¥¼ Gradio historyì—ì„œ ê°€ì ¸ì™€ì„œ ì €ì¥
                                # Chatbot íˆìŠ¤í† ë¦¬ëŠ” normalize_chatbot_historyë¡œ í•œ ë²ˆ ë” ì •ê·œí™”í•´ì„œ ì‚¬ìš©
                                conversation_list = []
                                try:
                                    normalized_history = normalize_chatbot_history(history)
                                    # ì´ë¯¸ {"role": ..., "content": ...} í˜•ì‹ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                                    for item in normalized_history:
                                        role = item.get("role")
                                        content = item.get("content", "")
                                        if role and isinstance(content, str) and content.strip():
                                            conversation_list.append({
                                                "role": role,
                                                "content": content.strip()
                                            })
                                except Exception as e:
                                    logger.warning(f"Failed to normalize chatbot history for scenario save: {e}")
                                
                                # ìµœê·¼ ëŒ€í™” í„´ (ë¬¸ë§¥ ì •ë³´) - contextì— ì €ì¥ (ìµœê·¼ 10í„´)
                                if hasattr(app_instance.brain, 'history') and app_instance.brain.history:
                                    recent_turns = []
                                    last_background = None
                                    last_visual_prompt = None
                                    history_turns = app_instance.brain.history.turns  # ìµœê·¼ 10í„´ë§Œ ìˆìŒ
                                    
                                    # ìµœê·¼ 10í„´ë§Œ contextì— ì €ì¥
                                    recent_history_turns = history_turns[-10:] if len(history_turns) > 10 else history_turns
                                    
                                    for idx, turn in enumerate(history_turns):
                                        if hasattr(turn, 'player_input') and hasattr(turn, 'character_speech'):
                                            turn_bg = getattr(turn, 'background', '')
                                            turn_visual = getattr(turn, 'visual_prompt', '')
                                            
                                            # ìµœê·¼ 10í„´ë§Œ recent_turnsì— ì €ì¥
                                            if turn in recent_history_turns:
                                                # ë§ˆì§€ë§‰ í„´ì˜ backgroundì™€ visual_prompt ì €ì¥
                                                if idx == len(history_turns) - 1:
                                                    last_background = turn_bg
                                                    last_visual_prompt = turn_visual
                                                
                                                recent_turns.append({
                                                    "turn_number": getattr(turn, 'turn_number', 0),
                                                    "player_input": turn.player_input,
                                                    "character_speech": getattr(turn, 'character_speech', ''),
                                                    "character_thought": getattr(turn, 'character_thought', ''),
                                                    "emotion": getattr(turn, 'emotion', 'neutral'),
                                                    "visual_prompt": turn_visual,
                                                    "background": turn_bg,
                                                    "stats_delta": getattr(turn, 'stats_delta', {})
                                                })
                                    
                                    # contextì— recent_turns ì €ì¥ (ìµœê·¼ 10í„´)
                                    context_data = {
                                        "recent_turns": recent_turns
                                    }
                                    if last_background:
                                        context_data["last_background"] = last_background
                                    elif state.current_background:
                                        context_data["last_background"] = state.current_background
                                    if last_visual_prompt:
                                        context_data["last_visual_prompt"] = last_visual_prompt
                                    
                                    scenario_data["context"] = context_data
                                
                                # conversation ì €ì¥ (ì „ì²´ ëŒ€í™”, Gradio history ê¸°ë°˜)
                                if not conversation_list:
                                    return i18n.get_text("msg_no_conversation_to_save")
                                
                                scenario_data["conversation"] = conversation_list
                            else:
                                return i18n.get_text("msg_game_not_started")
                            
                            # ì‹œë‚˜ë¦¬ì˜¤ ì €ì¥
                            scenario_name_clean = scenario_name.strip()
                            # .json í™•ì¥ì ì œê±° (save_scenarioì—ì„œ ìë™ ì¶”ê°€)
                            if scenario_name_clean.endswith('.json'):
                                scenario_name_clean = scenario_name_clean[:-5]
                            
                            if app_instance.save_scenario(scenario_data, scenario_name_clean):
                                # ë§ˆì§€ë§‰ ì´ë¯¸ì§€ë„ í•¨ê»˜ ì €ì¥ (ê°™ì€ ì´ë¦„ìœ¼ë¡œ PNG íŒŒì¼)
                                if app_instance.current_image is not None:
                                    try:
                                        from PIL import Image
                                        scenario_image_path = config.SCENARIOS_DIR / f"{scenario_name_clean}.png"
                                        
                                        # ì´ë¯¸ì§€ 1.5ë°° ë¦¬ì‚¬ì´ì¦ˆ (LANCZOS)
                                        width, height = app_instance.current_image.size
                                        resized_image = app_instance.current_image.resize((int(width * 1.5), int(height * 1.5)), Image.LANCZOS)
                                        
                                        resized_image.save(scenario_image_path, "PNG")
                                        logger.info(f"Scenario image saved to: {scenario_image_path}")
                                    except Exception as e:
                                        logger.warning(f"Failed to save scenario image: {e}")
                                
                                return i18n.get_text("msg_scenario_save_success", category="ui", name=scenario_name_clean)
                            else:
                                return i18n.get_text("msg_scenario_save_failed", category="ui")
                        except Exception as e:
                            logger.error(f"Failed to save scenario: {e}")
                            import traceback
                            logger.error(traceback.format_exc())
                            return i18n.get_text("msg_scenario_save_failed", category="ui")
                    
                    save_scenario_btn.click(
                        save_scenario_handler,
                        inputs=[scenario_save_name, chatbot],
                        outputs=[scenario_save_status]
                    )
                    
                    def update_chart_if_needed(new_chart):
                        """ì°¨íŠ¸ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°"""
                        if new_chart is not None:
                            return new_chart
                        return gr.skip()
                    
                    def update_image_if_needed(trigger_image):
                        """íŠ¸ë¦¬ê±°ì— ì´ë¯¸ì§€ê°€ ìˆì„ ë•Œë§Œ ë°˜í™˜, ì—†ìœ¼ë©´ ì—…ë°ì´íŠ¸ ì•ˆ í•¨ (ë¡œë”© ì´ìŠˆ ë””ë²„ê¹…ìš© ë¡œê·¸ í¬í•¨)"""
                        try:
                            logger.debug(f"[update_image_if_needed] called. trigger_image_is_none={trigger_image is None}, "
                                         f"has_current_image={app_instance.current_image is not None}")
                            if trigger_image is not None:
                                logger.debug("[update_image_if_needed] new image provided, showing retry button.")
                                # ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ì¬ì‹œë„ ë²„íŠ¼ë„ í‘œì‹œ
                                return trigger_image, gr.Button(visible=True)
                            # ì´ë¯¸ì§€ê°€ ì—†ì–´ë„ ì´ì „ ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ì¬ì‹œë„ ë²„íŠ¼ í‘œì‹œ
                            if app_instance.current_image is not None:
                                logger.debug("[update_image_if_needed] no new image, but current_image exists -> show retry.")
                                return gr.skip(), gr.Button(visible=True)
                            logger.debug("[update_image_if_needed] no image at all -> hide retry.")
                            return gr.skip(), gr.Button(visible=False)  # Gradio 6.x: ì—…ë°ì´íŠ¸ ê±´ë„ˆë›°ê¸°
                        except Exception as e:
                            import traceback
                            logger.error(f"[update_image_if_needed] ERROR: {e}")
                            logger.error(traceback.format_exc())
                            # ì‹¤íŒ¨ ì‹œì—ë„ ì²´ì¸ì„ ëŠì§€ ì•Šë„ë¡ ê¸°ë³¸ ë™ì‘ ë°˜í™˜
                            return gr.skip(), gr.Button(visible=bool(app_instance.current_image is not None))
                    
                    def retry_image_handler():
                        """ì´ë¯¸ì§€ ì¬ìƒì„± í•¸ë“¤ëŸ¬"""
                        if not app_instance.last_image_generation_info:
                            msg = i18n.get_text("retry_no_image", category="ui")
                            return gr.skip(), gr.Markdown(value=msg, visible=True), gr.Button(visible=True)
                        
                        try:
                            image, status_msg = app_instance.retry_image_generation()
                            if image:
                                return image, gr.Markdown(value=status_msg, visible=True), gr.Button(visible=True)
                            else:
                                return gr.skip(), gr.Markdown(value=status_msg, visible=True), gr.Button(visible=True)
                        except Exception as e:
                            logger.error(f"Failed to retry image generation: {e}")
                            err = i18n.get_text("retry_error", category="ui", error=str(e))
                            return gr.skip(), gr.Markdown(value=err, visible=True), gr.Button(visible=True)
                    
                    def save_current_image_handler():
                        """í˜„ì¬ í‘œì‹œëœ ì´ë¯¸ì§€ë¥¼ ê·¸ëŒ€ë¡œ image í´ë”ì— ì €ì¥ (í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ì—†ìŒ)"""
                        if app_instance.current_image is None:
                            msg = i18n.get_text("save_image_no_image", category="ui")
                            return gr.Markdown(value=msg, visible=True)
                        
                        try:
                            # ìƒíƒœì™€ ìƒê´€ì—†ì´ í˜„ì¬ ì´ë¯¸ì§€ë¥¼ ê·¸ëŒ€ë¡œ ì €ì¥ (ì˜¤ë²„ë ˆì´ ì—†ìŒ)
                            if app_instance.brain is not None and app_instance.brain.state is not None:
                                state = app_instance.brain.state
                                turn_number = getattr(state, "total_turns", None)
                            else:
                                turn_number = None

                            saved_path = app_instance._save_generated_image(app_instance.current_image, turn_number)
                            if saved_path:
                                msg = i18n.get_text("save_image_success", category="ui", path=saved_path)
                                return gr.Markdown(value=msg, visible=True)
                            else:
                                msg = i18n.get_text("save_image_fail", category="ui")
                                return gr.Markdown(value=msg, visible=True)
                        except Exception as e:
                            logger.error(f"Failed to save current image with overlay: {e}")
                            import traceback
                            logger.error(traceback.format_exc())
                            msg = i18n.get_text("save_image_error", category="ui", error=str(e))
                            return gr.Markdown(value=msg, visible=True)

                    def save_moment_image_handler():
                        """í˜„ì¬ ì´ë¯¸ì§€ë¥¼ 2ë°° í™•ëŒ€ + ëŒ€ì‚¬/ì†ë§ˆìŒ/í–‰ë™/ìƒíƒœ ì˜¤ë²„ë ˆì´ë¡œ ì €ì¥"""
                        if app_instance.current_image is None:
                            msg = i18n.get_text("save_image_no_image", category="ui")
                            return gr.Markdown(value=msg, visible=True)
                        try:
                            saved_path = app_instance.save_moment_image()
                            if saved_path:
                                msg = i18n.get_text("save_moment_success", category="ui", path=saved_path)
                                return gr.Markdown(value=msg, visible=True)
                            msg = i18n.get_text("save_moment_fail", category="ui")
                            return gr.Markdown(value=msg, visible=True)
                        except Exception as e:
                            logger.error(f"Failed to save moment image: {e}")
                            import traceback
                            logger.error(traceback.format_exc())
                            msg = i18n.get_text("save_moment_error", category="ui", error=str(e))
                            return gr.Markdown(value=msg, visible=True)

                    # ë©”ì¸ submit - ì´ë¯¸ì§€ì™€ ì°¨íŠ¸ëŠ” ë¹„ë™ê¸°ë¡œ ì—…ë°ì´íŠ¸
                    submit_btn.click(
                        on_submit,
                        inputs=[user_input, chatbot],
                        outputs=[chatbot, user_input, stats_display, thought_display, action_display, image_update_trigger, stats_chart, event_notification]
                    ).then(
                        update_image_if_needed,
                        inputs=[image_update_trigger],
                        outputs=[image_display, retry_image_btn]
                    ).then(
                        update_chart_async,
                        inputs=[chatbot],
                        outputs=[stats_chart]
                    )
                    
                    user_input.submit(
                        on_submit,
                        inputs=[user_input, chatbot],
                        outputs=[chatbot, user_input, stats_display, thought_display, action_display, image_update_trigger, stats_chart, event_notification]
                    ).then(
                        update_image_if_needed,
                        inputs=[image_update_trigger],
                        outputs=[image_display, retry_image_btn]
                    ).then(
                        update_chart_async,
                        inputs=[chatbot],
                        outputs=[stats_chart]
                    )

                    # ì¬ì‹œë„ ë²„íŠ¼ í´ë¦­ í•¸ë“¤ëŸ¬
                    retry_image_btn.click(
                        retry_image_handler,
                        inputs=[],
                        outputs=[image_display, retry_image_status, retry_image_btn]
                    )

                    # ì´ë¯¸ì§€ ì €ì¥ ë²„íŠ¼ í´ë¦­ í•¸ë“¤ëŸ¬
                    save_image_btn.click(
                        save_current_image_handler,
                        inputs=[],
                        outputs=[save_image_status]
                    )
                    
                    # ìˆœê°„ ì €ì¥ ë²„íŠ¼ í´ë¦­ í•¸ë“¤ëŸ¬
                    save_moment_btn.click(
                        save_moment_image_handler,
                        inputs=[],
                        outputs=[save_moment_status]
                    )
                    
                    # ì‹œë‚˜ë¦¬ì˜¤ ê°¤ëŸ¬ë¦¬ ì„ íƒ ì´ë²¤íŠ¸ ì—°ê²° (ëŒ€í™” íƒ­ ì»´í¬ë„ŒíŠ¸ ì •ì˜ ì´í›„)
                    def on_scenario_gallery_select(evt: gr.SelectData):
                        """ê°¤ëŸ¬ë¦¬ì—ì„œ ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒ ì‹œ"""
                        if evt.index is None:
                            return gr.skip(), gr.skip(), gr.skip(), gr.skip(), gr.skip(), gr.skip(), gr.skip(), gr.skip(), gr.skip(), gr.skip()
                        
                        import os
                        scenarios = app_instance.get_scenario_files()
                        # íŒŒì¼ ìˆ˜ì • ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ìµœì‹ ìˆœ ì •ë ¬ (ì—­ìˆœ)
                        scenario_paths = []
                        for scenario_name in scenarios:
                            scenario_path = config.SCENARIOS_DIR / f"{scenario_name}.json"
                            if scenario_path.exists():
                                mtime = os.path.getmtime(scenario_path)
                                scenario_paths.append((mtime, scenario_name))
                        scenario_paths.sort(reverse=True)
                        scenarios = [name for _, name in scenario_paths]
                        
                        if evt.index >= len(scenarios):
                            return gr.skip(), gr.skip(), gr.skip(), gr.skip(), gr.skip(), gr.skip(), gr.skip(), gr.skip(), gr.skip(), gr.skip()
                        
                        selected_scenario = scenarios[evt.index]
                        # continue_chat í•¨ìˆ˜ í˜¸ì¶œ
                        return continue_chat(selected_scenario)
                    
                    scenario_gallery.select(
                        fn=on_scenario_gallery_select,
                        outputs=[
                            setup_status, tabs,
                            chatbot, gr.Textbox(visible=False), stats_display, image_display,
                            gr.Textbox(visible=False), thought_display, action_display, stats_chart
                        ]
                    )
                    
                    # ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ì‹œ UI í™œì„±í™”
                    def enable_chat_ui():
                        if app_instance.model_loaded:
                            return (
                                gr.Button(interactive=True),  # submit_btn
                                gr.Textbox(interactive=True)  # user_input
                            )
                        return (
                            gr.Button(interactive=False),
                            gr.Textbox(interactive=False)
                        )
                    
                    # íƒ­ ì „í™˜ ì‹œ UI ìƒíƒœ í™•ì¸
                    chat_tab.select(
                        enable_chat_ui,
                        inputs=[],
                        outputs=[submit_btn, user_input]
                    )
                    
                
                # ========== íƒ­ 4: í™˜ê²½ì„¤ì • ==========
                with gr.Tab(i18n.get_text("tab_settings"), id="settings_tab"):
                    # ì–¸ì–´ ì„¤ì • ì„¹ì…˜ (ìµœìƒë‹¨)
                    gr.Markdown(f"## {i18n.get_text('language_settings')}")
                    language_radio = gr.Radio(
                        label=i18n.get_text("language_label"),
                        choices=["en", "kr"],
                        value=language,
                        info=i18n.get_text("language_info")
                    )
                    language_status = gr.Markdown("")
                    
                    def change_language(selected_language):
                        """ì–¸ì–´ ë³€ê²½ í•¸ë“¤ëŸ¬"""
                        try:
                            env_config = app_instance.load_env_config()
                            env_config["language"] = selected_language
                            if app_instance.save_env_config(env_config):
                                set_global_language(selected_language)
                                # Brain ì–¸ì–´ ì—…ë°ì´íŠ¸
                                if app_instance.brain is not None:
                                    app_instance.brain.language = selected_language
                                return i18n.get_text("msg_settings_save_success", category="ui")
                            else:
                                return i18n.get_text("msg_settings_save_failed", category="ui")
                        except Exception as e:
                            logger.error(f"Failed to change language: {e}")
                            return f"âŒ Language change failed: {str(e)}"
                    
                    language_radio.change(
                        change_language,
                        inputs=[language_radio],
                        outputs=[language_status]
                    )
                    
                    gr.Markdown("---")
                    gr.Markdown(f"## {i18n.get_text('settings_llm_title')}")
                    
                    # LLM ì„¤ì • ë¡œë“œ
                    llm_settings = env_config.get("llm_settings", {})
                    provider = llm_settings.get("provider", "ollama")
                    ollama_model = llm_settings.get("ollama_model", "kwangsuklee/Qwen2.5-14B-Gutenberg-1e-Delta.Q5_K_M:latest")
                    openrouter_model = llm_settings.get("openrouter_model", "cognitivecomputations/dolphin-mistral-24b-venice-edition:free")
                    llm_temperature = float(llm_settings.get("temperature", config.LLM_CONFIG["temperature"]))
                    llm_top_p = float(llm_settings.get("top_p", config.LLM_CONFIG["top_p"]))
                    llm_max_tokens = int(llm_settings.get("max_tokens", config.LLM_CONFIG["max_tokens"]))
                    llm_presence_penalty = float(llm_settings.get("presence_penalty", config.LLM_CONFIG["presence_penalty"]))
                    llm_frequency_penalty = float(llm_settings.get("frequency_penalty", config.LLM_CONFIG["frequency_penalty"]))
                    # API í‚¤ëŠ” íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
                    openrouter_api_key = app_instance._load_openrouter_api_key()
                    
                    llm_provider = gr.Radio(
                        label=i18n.get_text("llm_provider"),
                        choices=["ollama", "openrouter"],
                        value=provider,
                        info=i18n.get_text("llm_provider_info")
                    )
                    
                    with gr.Group(visible=(provider == "ollama")) as ollama_group:
                        ollama_model_input = gr.Textbox(
                            label=i18n.get_text("ollama_model"),
                            value=ollama_model,
                            placeholder=i18n.get_text("ollama_model_placeholder"),
                            info=i18n.get_text("ollama_model_info")
                        )
                    
                    with gr.Group(visible=(provider == "openrouter")) as openrouter_group:
                        openrouter_api_key_input = gr.Textbox(
                            label=i18n.get_text("openrouter_api_key"),
                            value=openrouter_api_key,
                            placeholder=i18n.get_text("openrouter_api_key_placeholder"),
                            type="password",
                            info=i18n.get_text("openrouter_api_key_info")
                        )
                        openrouter_model_input = gr.Textbox(
                            label=i18n.get_text("openrouter_model"),
                            value=openrouter_model,
                            placeholder=i18n.get_text("openrouter_model_placeholder"),
                            info=i18n.get_text("openrouter_model_info")
                        )
                    
                    # ê³µí†µ LLM íŒŒë¼ë¯¸í„° (ollama/openrouter ê³µí†µ)
                    with gr.Row():
                        temperature_input = gr.Number(
                            label=i18n.get_text("llm_temperature"),
                            value=llm_temperature,
                            minimum=0.0,
                            maximum=2.0,
                            step=0.05,
                            info=i18n.get_text("llm_temperature_info")
                        )
                        top_p_input = gr.Number(
                            label=i18n.get_text("llm_top_p"),
                            value=llm_top_p,
                            minimum=0.0,
                            maximum=1.0,
                            step=0.01,
                            info=i18n.get_text("llm_top_p_info")
                        )
                    with gr.Row():
                        max_tokens_input = gr.Number(
                            label=i18n.get_text("llm_max_tokens"),
                            value=llm_max_tokens,
                            minimum=1,
                            maximum=4000,
                            step=50,
                            info=i18n.get_text("llm_max_tokens_info")
                        )
                        presence_penalty_input = gr.Number(
                            label=i18n.get_text("llm_presence_penalty"),
                            value=llm_presence_penalty,
                            minimum=-2.0,
                            maximum=2.0,
                            step=0.05,
                            info=i18n.get_text("llm_presence_penalty_info")
                        )
                        frequency_penalty_input = gr.Number(
                            label=i18n.get_text("llm_frequency_penalty"),
                            value=llm_frequency_penalty,
                            minimum=-2.0,
                            maximum=2.0,
                            step=0.05,
                            info=i18n.get_text("llm_frequency_penalty_info")
                        )

                    # Provider ë³€ê²½ ì‹œ UI í‘œì‹œ/ìˆ¨ê¹€
                    def update_provider_ui(selected_provider):
                        return (
                            gr.Group(visible=(selected_provider == "ollama")),
                            gr.Group(visible=(selected_provider == "openrouter"))
                        )
                    
                    llm_provider.change(
                        update_provider_ui,
                        inputs=[llm_provider],
                        outputs=[ollama_group, openrouter_group]
                    )
                    
                    settings_status = gr.Markdown("")
                    save_settings_btn = gr.Button(i18n.get_text("btn_save_settings"), variant="primary")
                    
                    def save_llm_settings(provider_val, ollama_model_val, openrouter_key_val, openrouter_model_val, temperature_val, top_p_val, max_tokens_val, presence_penalty_val, frequency_penalty_val):
                        """LLM ì„¤ì • ì €ì¥"""
                        try:
                            env_config = app_instance.load_env_config()
                            
                            # OpenRouter API í‚¤ëŠ” ë³„ë„ íŒŒì¼ì— ì €ì¥
                            if provider_val == "openrouter" and openrouter_key_val:
                                if not app_instance._save_openrouter_api_key(openrouter_key_val):
                                    return i18n.get_text("msg_openrouter_api_key_save_failed")
                            
                            # LLM ì„¤ì • ì—…ë°ì´íŠ¸ (API í‚¤ëŠ” ì œì™¸)
                            # ìˆ˜ì¹˜í˜• íŒŒë¼ë¯¸í„° ì •ê·œí™”
                            def to_float(val, default):
                                try:
                                    return float(val)
                                except (TypeError, ValueError):
                                    return default
                            def to_int(val, default):
                                try:
                                    return int(val)
                                except (TypeError, ValueError):
                                    return default
                            
                            env_config["llm_settings"] = {
                                "provider": provider_val,
                                "ollama_model": ollama_model_val or "kwangsuklee/Qwen2.5-14B-Gutenberg-1e-Delta.Q5_K_M:latest",
                                "openrouter_model": openrouter_model_val or "cognitivecomputations/dolphin-mistral-24b-venice-edition:free",
                                "temperature": to_float(temperature_val, config.LLM_CONFIG["temperature"]),
                                "top_p": to_float(top_p_val, config.LLM_CONFIG["top_p"]),
                                "max_tokens": to_int(max_tokens_val, config.LLM_CONFIG["max_tokens"]),
                                "presence_penalty": to_float(presence_penalty_val, config.LLM_CONFIG["presence_penalty"]),
                                "frequency_penalty": to_float(frequency_penalty_val, config.LLM_CONFIG["frequency_penalty"]),
                            }
                            
                            # í™˜ê²½ì„¤ì • ì €ì¥
                            if app_instance.save_env_config(env_config):
                                # Brain ì¬ì´ˆê¸°í™” (ìƒˆ ì„¤ì • ì ìš©)
                                try:
                                    if app_instance.brain is not None:
                                        # ê¸°ì¡´ Brainì˜ memory_managerë¥¼ ìƒˆ ì„¤ì •ìœ¼ë¡œ ì¬ì´ˆê¸°í™”
                                        llm_settings = env_config["llm_settings"]
                                        # API í‚¤ëŠ” íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
                                        api_key = app_instance._load_openrouter_api_key() if llm_settings["provider"] == "openrouter" else None
                                        app_instance.brain.memory_manager = MemoryManager(
                                            dev_mode=app_instance.dev_mode,
                                            provider=llm_settings["provider"],
                                            model_name=llm_settings["ollama_model"] if llm_settings["provider"] == "ollama" else llm_settings["openrouter_model"],
                                            api_key=api_key
                                        )
                                        
                                        # ëª¨ë¸ ë¡œë“œ ì‹œë„ (OpenRouter ì‹¤íŒ¨ ì‹œ Ollamaë¡œ í´ë°±)
                                        result = app_instance.brain.memory_manager.load_model()
                                        if result is None and llm_settings["provider"] == "openrouter":
                                            logger.warning("OpenRouter ì—°ê²° ì‹¤íŒ¨, Ollamaë¡œ í´ë°± ì‹œë„...")
                                            # Ollamaë¡œ í´ë°±
                                            env_config["llm_settings"]["provider"] = "ollama"
                                            app_instance.brain.memory_manager = MemoryManager(
                                                dev_mode=app_instance.dev_mode,
                                                provider="ollama",
                                                model_name=llm_settings["ollama_model"]
                                            )
                                            result = app_instance.brain.memory_manager.load_model()
                                            if result is None:
                                                return i18n.get_text("msg_openrouter_fallback_failed")
                                            # í´ë°± ì„¤ì • ì €ì¥
                                            app_instance.save_env_config(env_config)
                                            return i18n.get_text("msg_openrouter_fallback_success")
                                        
                                        app_instance.model_loaded = (result is not None)
                                        if app_instance.model_loaded:
                                            return i18n.get_text("msg_settings_saved_with_provider", provider=llm_settings['provider'].upper())
                                        else:
                                            return i18n.get_text("msg_settings_saved_but_connection_failed", provider=llm_settings['provider'].upper())
                                    else:
                                        return i18n.get_text("msg_settings_saved_next_start")
                                except Exception as e:
                                    logger.error(f"Failed to reinitialize Brain: {e}")
                                    return i18n.get_text("msg_settings_saved_reconnect_failed", error=str(e))
                            else:
                                return i18n.get_text("msg_settings_save_failed", error="")
                        except Exception as e:
                            logger.error(f"Failed to save LLM settings: {e}")
                            return i18n.get_text("msg_settings_save_failed", error=f": {str(e)}")
                    
                    save_settings_btn.click(
                        save_llm_settings,
                        inputs=[llm_provider, ollama_model_input, openrouter_api_key_input, openrouter_model_input, temperature_input, top_p_input, max_tokens_input, presence_penalty_input, frequency_penalty_input],
                        outputs=[settings_status]
                    )
                    
                    gr.Markdown("---")
                    gr.Markdown("## ComfyUI ì„¤ì •")
                    
                    # ìŠ¤íƒ€ì¼ë³„ ê¸°ë³¸ ì„¤ì •ê°’ ì •ì˜
                    STYLE_CONFIGS = {
                        "SDXL": {
                            "workflow": "comfyui_2d.json",
                            "workflow_lora": "comfyui_2d_lora.json",
                            "model_name": "Zeniji_Mix K-Webtoon.safetensors",
                            "vae_name": "sdxl_vae.safetensors",
                            "clip_name": "",
                            "lora_name": "",
                            "lora_strength_model": 1.0,
                            "steps": 30,
                            "cfg": 5,
                            "sampler_name": "euler",
                            "scheduler": "simple"
                        },
                        "QWEN/Z-image": {
                            "workflow": "comfyui_real.json",
                            "workflow_lora": "comfyui_real_lora.json",
                            "model_name": "Zeniji_mix_ZiT_v1.safetensors",
                            "vae_name": "zImage_vae.safetensors",
                            "clip_name": "zImage_textEncoder.safetensors",
                            "lora_name": "ZiT_K_beauty_A.safetensors",
                            "lora_strength_model": 1.0,
                            "steps": 9,
                            "cfg": 1,
                            "sampler_name": "euler",
                            "scheduler": "simple"
                        }
                    }
                    
                    # ComfyUI ì„¤ì • ë¡œë“œ
                    comfyui_settings = env_config.get("comfyui_settings", {})
                    comfyui_port = comfyui_settings.get("server_port", 8000)
                    comfyui_style = comfyui_settings.get("style", "QWEN/Z-image")
                    comfyui_use_lora = comfyui_settings.get("use_lora", False)
                    style_defaults = STYLE_CONFIGS.get(comfyui_style, STYLE_CONFIGS["QWEN/Z-image"])
                    # ìŠ¤íƒ€ì¼ë³„ ì„¤ì • ë¡œë“œ (ê°œë³„ -> ê³µí†µ -> ê¸°ë³¸ê°’ ìˆœ)
                    if comfyui_style == "SDXL":
                        default_workflow = style_defaults["workflow_lora"] if comfyui_use_lora else style_defaults["workflow"]
                        workflow_path = comfyui_settings.get("workflow_path_sdxl") or f"workflows/{default_workflow}"
                        comfyui_model = comfyui_settings.get("model_name_sdxl") or style_defaults["model_name"]
                        comfyui_vae = comfyui_settings.get("vae_name_sdxl") or style_defaults["vae_name"]
                        comfyui_clip = comfyui_settings.get("clip_name_sdxl") or style_defaults["clip_name"]
                        comfyui_lora_name = comfyui_settings.get("lora_name_sdxl") or style_defaults["lora_name"]
                        comfyui_lora_strength_model = comfyui_settings.get("lora_strength_model_sdxl")
                        if comfyui_lora_strength_model in (None, ""):
                            comfyui_lora_strength_model = style_defaults["lora_strength_model"]
                        comfyui_steps = comfyui_settings.get("steps_sdxl") or style_defaults["steps"]
                        comfyui_cfg = comfyui_settings.get("cfg_sdxl") or style_defaults["cfg"]
                        comfyui_sampler = comfyui_settings.get("sampler_name_sdxl") or style_defaults["sampler_name"]
                        comfyui_scheduler = comfyui_settings.get("scheduler_sdxl") or style_defaults["scheduler"]
                    else:
                        default_workflow = style_defaults["workflow_lora"] if comfyui_use_lora else style_defaults["workflow"]
                        workflow_path = comfyui_settings.get("workflow_path_qwen") or f"workflows/{default_workflow}"
                        comfyui_model = comfyui_settings.get("model_name_qwen") or style_defaults["model_name"]
                        comfyui_vae = comfyui_settings.get("vae_name_qwen") or style_defaults["vae_name"]
                        comfyui_clip = comfyui_settings.get("clip_name_qwen") or style_defaults["clip_name"]
                        comfyui_lora_name = comfyui_settings.get("lora_name_qwen") or style_defaults["lora_name"]
                        comfyui_lora_strength_model = comfyui_settings.get("lora_strength_model_qwen")
                        if comfyui_lora_strength_model in (None, ""):
                            comfyui_lora_strength_model = style_defaults["lora_strength_model"]
                        comfyui_steps = comfyui_settings.get("steps_qwen") or style_defaults["steps"]
                        comfyui_cfg = comfyui_settings.get("cfg_qwen") or style_defaults["cfg"]
                        comfyui_sampler = comfyui_settings.get("sampler_name_qwen") or style_defaults["sampler_name"]
                        comfyui_scheduler = comfyui_settings.get("scheduler_qwen") or style_defaults["scheduler"]
                    comfyui_quality_tag = comfyui_settings.get("quality_tag", "masterpiece, best quality, very awa")
                    comfyui_negative_prompt = comfyui_settings.get("negative_prompt", "(bad quality, worst quality, low quality), 3d, 3d rendering, manga, cartoon, 2d, fatty, thick body, big body, huge breasts, muscular, mole, watermark, text")
                    comfyui_upscale_model = comfyui_settings.get("upscale_model_name", "4x-UltraSharp.pth")
                    
                    with gr.Row():
                        with gr.Column():
                            comfyui_port_input = gr.Number(
                                label=i18n.get_text("comfyui_port"),
                                value=comfyui_port,
                                minimum=1,
                                maximum=65535,
                                step=1,
                                info=i18n.get_text("comfyui_port_info")
                            )
                            comfyui_style_input = gr.Radio(
                                label=i18n.get_text("comfyui_style"),
                                choices=["QWEN/Z-image", "SDXL"],
                                value=comfyui_style,
                                info=i18n.get_text("comfyui_style_info")
                            )
                            comfyui_use_lora_input = gr.Checkbox(
                                label=i18n.get_text("comfyui_use_lora") if hasattr(i18n, "get_text") else "Use LoRA",
                                value=comfyui_use_lora
                            )
                            with gr.Group(visible=(comfyui_style == "SDXL")) as comfyui_2d_group:
                                comfyui_quality_tag_input = gr.Textbox(
                                    label=i18n.get_text("comfyui_quality_tag"),
                                    value=comfyui_quality_tag,
                                    placeholder=i18n.get_text("comfyui_quality_tag_placeholder"),
                                    info=i18n.get_text("comfyui_quality_tag_info")
                                )
                                comfyui_negative_prompt_input = gr.Textbox(
                                    label=i18n.get_text("comfyui_negative_prompt"),
                                    value=comfyui_negative_prompt,
                                    placeholder=i18n.get_text("comfyui_negative_prompt_placeholder"),
                                    info=i18n.get_text("comfyui_negative_prompt_info"),
                                    lines=3
                                )
                                comfyui_upscale_model_input = gr.Textbox(
                                    label=i18n.get_text("comfyui_upscale_model"),
                                    value=comfyui_upscale_model,
                                    placeholder=i18n.get_text("comfyui_upscale_model_placeholder"),
                                    info=i18n.get_text("comfyui_upscale_model_info")
                                )
                            comfyui_model_input = gr.Textbox(
                                label=i18n.get_text("comfyui_model"),
                                value=comfyui_model,
                                placeholder=i18n.get_text("comfyui_model_placeholder"),
                                info=i18n.get_text("comfyui_model_info")
                            )
                            comfyui_vae_input = gr.Textbox(
                                label=i18n.get_text("comfyui_vae"),
                                value=comfyui_vae,
                                placeholder=i18n.get_text("comfyui_vae_placeholder"),
                                info=i18n.get_text("comfyui_vae_info")
                            )
                            comfyui_clip_input = gr.Textbox(
                                label=i18n.get_text("comfyui_clip"),
                                value=comfyui_clip,
                                placeholder=i18n.get_text("comfyui_clip_placeholder"),
                                info=i18n.get_text("comfyui_clip_info"),
                                visible=(comfyui_style != "SDXL")
                            )
                            with gr.Group(visible=comfyui_use_lora) as comfyui_lora_group:
                                comfyui_lora_name_input = gr.Textbox(
                                    label=i18n.get_text("comfyui_lora_name"),
                                    value=comfyui_lora_name,
                                    placeholder=i18n.get_text("comfyui_lora_name_placeholder"),
                                    info=i18n.get_text("comfyui_lora_name_info")
                                )
                        with gr.Column():
                            comfyui_steps_input = gr.Number(
                                label=i18n.get_text("comfyui_steps"),
                                value=comfyui_steps,
                                minimum=1,
                                maximum=100,
                                step=1,
                                info=i18n.get_text("comfyui_steps_info")
                            )
                            comfyui_cfg_input = gr.Number(
                                label=i18n.get_text("comfyui_cfg"),
                                value=comfyui_cfg,
                                minimum=0.1,
                                maximum=20.0,
                                step=0.1,
                                info=i18n.get_text("comfyui_cfg_info")
                            )
                            comfyui_sampler_input = gr.Textbox(
                                label=i18n.get_text("comfyui_sampler"),
                                value=comfyui_sampler,
                                placeholder=i18n.get_text("comfyui_sampler_placeholder"),
                                info=i18n.get_text("comfyui_sampler_info")
                            )
                            comfyui_scheduler_input = gr.Textbox(
                                label=i18n.get_text("comfyui_scheduler"),
                                value=comfyui_scheduler,
                                placeholder=i18n.get_text("comfyui_scheduler_placeholder"),
                                info=i18n.get_text("comfyui_scheduler_info")
                            )
                            with comfyui_lora_group:
                                comfyui_lora_strength_model_input = gr.Number(
                                    label=i18n.get_text("comfyui_lora_strength_model"),
                                    value=comfyui_lora_strength_model,
                                    minimum=-10.0,
                                    maximum=10.0,
                                    step=0.01,
                                    info=i18n.get_text("comfyui_lora_strength_model_info")
                                )
                    
                    # ìŠ¤íƒ€ì¼ ë³€ê²½ ì‹œ UI ì—…ë°ì´íŠ¸
                    def update_style_ui(selected_style):
                        """ìŠ¤íƒ€ì¼ ë³€ê²½ ì‹œ ê´€ë ¨ ì„¤ì • ìë™ ë³€ê²½"""
                        style_defaults = STYLE_CONFIGS.get(selected_style, STYLE_CONFIGS["QWEN/Z-image"])
                        style_key = "sdxl" if selected_style == "SDXL" else "qwen"
                        # í˜„ì¬ ì„¤ì •ì—ì„œ ìŠ¤íƒ€ì¼ë³„ sampler/scheduler ê°€ì ¸ì˜¤ê¸°
                        env_config = app_instance.load_env_config()
                        comfyui_settings = env_config.get("comfyui_settings", {})
                        if selected_style == "SDXL":
                            sampler_val = comfyui_settings.get("sampler_name_sdxl") or comfyui_settings.get("sampler_name") or style_defaults["sampler_name"]
                            scheduler_val = comfyui_settings.get("scheduler_sdxl") or comfyui_settings.get("scheduler") or style_defaults["scheduler"]
                        else:
                            sampler_val = comfyui_settings.get("sampler_name_qwen") or comfyui_settings.get("sampler_name") or style_defaults["sampler_name"]
                            scheduler_val = comfyui_settings.get("scheduler_qwen") or comfyui_settings.get("scheduler") or style_defaults["scheduler"]
                        model_val = comfyui_settings.get(f"model_name_{style_key}") or style_defaults["model_name"]
                        vae_val = comfyui_settings.get(f"vae_name_{style_key}") or style_defaults["vae_name"]
                        clip_val = comfyui_settings.get(f"clip_name_{style_key}") or style_defaults["clip_name"]
                        lora_val = comfyui_settings.get(f"lora_name_{style_key}") or style_defaults.get("lora_name", "")
                        lora_strength_val = comfyui_settings.get(f"lora_strength_model_{style_key}")
                        if lora_strength_val in (None, ""):
                            lora_strength_val = style_defaults.get("lora_strength_model", 1.0)
                        steps_val = comfyui_settings.get(f"steps_{style_key}") or style_defaults["steps"]
                        cfg_val = comfyui_settings.get(f"cfg_{style_key}") or style_defaults["cfg"]
                        
                        return (
                            gr.Textbox(value=model_val),  # ëª¨ë¸
                            gr.Textbox(value=vae_val),  # VAE
                            gr.Textbox(value=clip_val, visible=(selected_style != "SDXL")),  # CLIP (SDXLì¼ ë•Œ ìˆ¨ê¹€)
                            gr.Textbox(value=lora_val),  # LoRA ì´ë¦„
                            gr.Number(value=steps_val),  # Steps
                            gr.Number(value=cfg_val),  # CFG
                            gr.Textbox(value=sampler_val),  # Sampler
                            gr.Textbox(value=scheduler_val),  # Scheduler
                            gr.Number(value=lora_strength_val),  # LoRA ê°•ë„
                            gr.Group(visible=(selected_style == "SDXL")),  # 2D ì„¤ì • ê·¸ë£¹
                        )
                    
                    comfyui_style_input.change(
                        update_style_ui,
                        inputs=[comfyui_style_input],
                        outputs=[comfyui_model_input, comfyui_vae_input, comfyui_clip_input, comfyui_lora_name_input, comfyui_steps_input, comfyui_cfg_input, comfyui_sampler_input, comfyui_scheduler_input, comfyui_lora_strength_model_input, comfyui_2d_group]
                    )
                    
                    # LoRA í† ê¸€ ë³€ê²½ ì‹œ UI ì—…ë°ì´íŠ¸ (LoRA ê·¸ë£¹ë§Œ)
                    def update_lora_toggle(use_lora):
                        return gr.Group(visible=use_lora)
                    
                    comfyui_use_lora_input.change(
                        update_lora_toggle,
                        inputs=[comfyui_use_lora_input],
                        outputs=[comfyui_lora_group]
                    )
                    
                    comfyui_status = gr.Markdown("")
                    save_comfyui_btn = gr.Button(i18n.get_text("btn_save_comfyui"), variant="primary")
                    
                    def save_comfyui_settings(port_val, style_val, use_lora_val, model_val, vae_val, clip_val, lora_name_val, lora_strength_val, steps_val, cfg_val, sampler_val, scheduler_val, quality_tag_val, negative_prompt_val, upscale_model_val):
                        """ComfyUI ì„¤ì • ì €ì¥"""
                        try:
                            env_config = app_instance.load_env_config()
                            
                            # ComfyUI ì„¤ì • ì—…ë°ì´íŠ¸
                            if "comfyui_settings" not in env_config:
                                env_config["comfyui_settings"] = {}
                            
                            # ìŠ¤íƒ€ì¼ë³„ ê¸°ë³¸ê°’ ë¡œë“œ
                            style_val = style_val or "QWEN/Z-image"
                            style_key = "sdxl" if style_val == "SDXL" else "qwen"
                            style_defaults = STYLE_CONFIGS.get(style_val, STYLE_CONFIGS["QWEN/Z-image"])
                            # LoRA í† ê¸€ì— ë”°ë¼ ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° ì„ íƒ
                            use_lora = bool(use_lora_val)
                            base_workflow = style_defaults["workflow_lora"] if use_lora else style_defaults["workflow"]
                            workflow_path = f"workflows/{base_workflow}"
                            model_default = style_defaults["model_name"]
                            vae_default = style_defaults["vae_name"]
                            clip_default = style_defaults["clip_name"]
                            lora_default = style_defaults.get("lora_name", "")
                            lora_strength_default = style_defaults.get("lora_strength_model", 1.0)
                            steps_default = style_defaults["steps"]
                            cfg_default = style_defaults["cfg"]
                            
                            model_value = model_val or model_default
                            vae_value = vae_val or vae_default
                            clip_value = clip_val or clip_default
                            lora_value = lora_name_val or lora_default
                            try:
                                lora_strength_value = float(lora_strength_val) if lora_strength_val not in (None, "") else lora_strength_default
                            except (TypeError, ValueError):
                                lora_strength_value = lora_strength_default
                            steps_value = int(steps_val) if steps_val not in (None, "") else steps_default
                            cfg_value = float(cfg_val) if cfg_val not in (None, "") else cfg_default
                            
                            env_config["comfyui_settings"]["server_port"] = int(port_val) if port_val else 8000
                            env_config["comfyui_settings"]["style"] = style_val
                            
                            # ì „ì—­ LoRA ì‚¬ìš© ì—¬ë¶€ ì €ì¥
                            env_config["comfyui_settings"]["use_lora"] = use_lora
                            
                            env_config["comfyui_settings"][f"workflow_path_{style_key}"] = workflow_path
                            env_config["comfyui_settings"][f"model_name_{style_key}"] = model_value
                            env_config["comfyui_settings"][f"vae_name_{style_key}"] = vae_value
                            env_config["comfyui_settings"][f"clip_name_{style_key}"] = clip_value
                            env_config["comfyui_settings"][f"lora_name_{style_key}"] = lora_value
                            env_config["comfyui_settings"][f"lora_strength_model_{style_key}"] = lora_strength_value
                            env_config["comfyui_settings"][f"steps_{style_key}"] = steps_value
                            env_config["comfyui_settings"][f"cfg_{style_key}"] = cfg_value
                            # ìŠ¤íƒ€ì¼ë³„ë¡œ sampler/scheduler ì €ì¥
                            if style_val == "SDXL":
                                env_config["comfyui_settings"]["sampler_name_sdxl"] = sampler_val or "euler"
                                env_config["comfyui_settings"]["scheduler_sdxl"] = scheduler_val or "simple"
                            else:
                                env_config["comfyui_settings"]["sampler_name_qwen"] = sampler_val or "euler"
                                env_config["comfyui_settings"]["scheduler_qwen"] = scheduler_val or "simple"
                            env_config["comfyui_settings"]["quality_tag"] = quality_tag_val or ""
                            env_config["comfyui_settings"]["negative_prompt"] = negative_prompt_val or ""
                            env_config["comfyui_settings"]["upscale_model_name"] = upscale_model_val or "4x-UltraSharp.pth"
                            
                            # í™˜ê²½ì„¤ì • ì €ì¥
                            if app_instance.save_env_config(env_config):
                                # ComfyClient ì¬ì´ˆê¸°í™” (ìƒˆ ì„¤ì • ì ìš©)
                                try:
                                    if app_instance.comfy_client is not None:
                                        server_address = f"127.0.0.1:{env_config['comfyui_settings']['server_port']}"
                                        style = env_config['comfyui_settings'].get('style', 'QWEN/Z-image')
                                        style_defaults = STYLE_CONFIGS.get(style, STYLE_CONFIGS["QWEN/Z-image"])
                                        # ìŠ¤íƒ€ì¼ë³„ sampler/scheduler ê°€ì ¸ì˜¤ê¸° (í•˜ìœ„ í˜¸í™˜ì„± í¬í•¨)
                                        if style == "SDXL":
                                            # ì €ì¥ëœ ê²½ë¡œê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©, ì—†ìœ¼ë©´ LoRA í† ê¸€ì— ë”°ë¼ ì„ íƒ
                                            use_lora = env_config['comfyui_settings'].get('use_lora', False)
                                            default_workflow = style_defaults["workflow_lora"] if use_lora else style_defaults["workflow"]
                                            workflow_path = env_config['comfyui_settings'].get('workflow_path_sdxl') or f"workflows/{default_workflow}"
                                            model_name = env_config['comfyui_settings'].get('model_name_sdxl') or style_defaults['model_name']
                                            vae_name = env_config['comfyui_settings'].get('vae_name_sdxl') or style_defaults['vae_name']
                                            clip_name = env_config['comfyui_settings'].get('clip_name_sdxl') or style_defaults['clip_name']
                                            # LoRA í† ê¸€ì— ë”°ë¼ ë¡œë¼ ì ìš©/ë¹„ì ìš©
                                            if env_config['comfyui_settings'].get('use_lora', False):
                                                lora_name = env_config['comfyui_settings'].get('lora_name_sdxl') or style_defaults.get('lora_name', '')
                                                lora_strength_model = env_config['comfyui_settings'].get('lora_strength_model_sdxl')
                                                if lora_strength_model in (None, ""):
                                                    lora_strength_model = style_defaults.get('lora_strength_model', 1.0)
                                            else:
                                                lora_name = None
                                                lora_strength_model = None
                                            steps = env_config['comfyui_settings'].get('steps_sdxl') or style_defaults['steps']
                                            cfg = env_config['comfyui_settings'].get('cfg_sdxl') or style_defaults['cfg']
                                            sampler_name = env_config['comfyui_settings'].get('sampler_name_sdxl') or style_defaults['sampler_name']
                                            scheduler = env_config['comfyui_settings'].get('scheduler_sdxl') or style_defaults['scheduler']
                                        else:
                                            # ì €ì¥ëœ ê²½ë¡œê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©, ì—†ìœ¼ë©´ LoRA í† ê¸€ì— ë”°ë¼ ì„ íƒ
                                            use_lora = env_config['comfyui_settings'].get('use_lora', False)
                                            default_workflow = style_defaults["workflow_lora"] if use_lora else style_defaults["workflow"]
                                            workflow_path = env_config['comfyui_settings'].get('workflow_path_qwen') or f"workflows/{default_workflow}"
                                            model_name = env_config['comfyui_settings'].get('model_name_qwen') or style_defaults['model_name']
                                            vae_name = env_config['comfyui_settings'].get('vae_name_qwen') or style_defaults['vae_name']
                                            clip_name = env_config['comfyui_settings'].get('clip_name_qwen') or style_defaults['clip_name']
                                            # LoRA í† ê¸€ì— ë”°ë¼ ë¡œë¼ ì ìš©/ë¹„ì ìš©
                                            if env_config['comfyui_settings'].get('use_lora', False):
                                                lora_name = env_config['comfyui_settings'].get('lora_name_qwen') or style_defaults.get('lora_name', '')
                                                lora_strength_model = env_config['comfyui_settings'].get('lora_strength_model_qwen')
                                                if lora_strength_model in (None, ""):
                                                    lora_strength_model = style_defaults.get('lora_strength_model', 1.0)
                                            else:
                                                lora_name = None
                                                lora_strength_model = None
                                            steps = env_config['comfyui_settings'].get('steps_qwen') or style_defaults['steps']
                                            cfg = env_config['comfyui_settings'].get('cfg_qwen') or style_defaults['cfg']
                                            sampler_name = env_config['comfyui_settings'].get('sampler_name_qwen') or style_defaults['sampler_name']
                                            scheduler = env_config['comfyui_settings'].get('scheduler_qwen') or style_defaults['scheduler']
                                        quality_tag = env_config['comfyui_settings'].get('quality_tag', '')
                                        negative_prompt = env_config['comfyui_settings'].get('negative_prompt', '')
                                        upscale_model_name = env_config['comfyui_settings'].get('upscale_model_name', '4x-UltraSharp.pth')
                                        app_instance.comfy_client = ComfyClient(
                                            server_address=server_address,
                                            workflow_path=workflow_path,
                                            model_name=model_name,
                                            steps=steps,
                                            cfg=cfg,
                                            sampler_name=sampler_name,
                                            scheduler=scheduler,
                                            vae_name=vae_name,
                                            clip_name=clip_name,
                                            style=style,
                                            quality_tag=quality_tag,
                                            negative_prompt=negative_prompt,
                                            upscale_model_name=upscale_model_name,
                                            lora_name=lora_name,
                                            lora_strength_model=lora_strength_model
                                        )
                                        # LoRA ì‚¬ìš© ì—¬ë¶€ì— ë”°ë¼ ë¡œê·¸ ë©”ì‹œì§€ ë¶„ë¦¬
                                        if lora_name is not None:
                                            logger.info(
                                                f"ComfyClient ì¬ì´ˆê¸°í™” ì™„ë£Œ: {server_address}, "
                                                f"workflow: {workflow_path}, model: {model_name}, vae: {vae_name}, clip: {clip_name}, "
                                                f"LoRA enabled: name={lora_name}, strength_model={lora_strength_model}, "
                                                f"steps: {steps}, cfg: {cfg}, sampler: {sampler_name}, scheduler: {scheduler}"
                                            )
                                        else:
                                            logger.info(
                                                f"ComfyClient ì¬ì´ˆê¸°í™” ì™„ë£Œ: {server_address}, "
                                                f"workflow: {workflow_path}, model: {model_name}, vae: {vae_name}, clip: {clip_name}, "
                                                f"LoRA disabled, steps: {steps}, cfg: {cfg}, sampler: {sampler_name}, scheduler: {scheduler}"
                                            )
                                    return i18n.get_text("msg_comfyui_settings_saved")
                                except Exception as e:
                                    logger.error(f"Failed to reinitialize ComfyClient: {e}")
                                    return i18n.get_text("msg_comfyui_settings_saved_reconnect_failed", error=str(e))
                            else:
                                return i18n.get_text("msg_comfyui_settings_save_failed", error="")
                        except Exception as e:
                            logger.error(f"Failed to save ComfyUI settings: {e}")
                            return i18n.get_text("msg_comfyui_settings_save_failed", error=f": {str(e)}")
                    
                    save_comfyui_btn.click(
                        save_comfyui_settings,
                        inputs=[comfyui_port_input, comfyui_style_input, comfyui_use_lora_input, comfyui_model_input, comfyui_vae_input, comfyui_clip_input, comfyui_lora_name_input, comfyui_lora_strength_model_input, comfyui_steps_input, comfyui_cfg_input, comfyui_sampler_input, comfyui_scheduler_input, comfyui_quality_tag_input, comfyui_negative_prompt_input, comfyui_upscale_model_input],
                        outputs=[comfyui_status]
                    )
            
            # ì²« íƒ­ì˜ ë²„íŠ¼ í´ë¦­ ì‹œ ëŒ€í™” íƒ­ ì»´í¬ë„ŒíŠ¸ ì—…ë°ì´íŠ¸ (íƒ­ ë°–ì—ì„œ ì •ì˜)
            start_btn.click(
                app_instance.validate_and_start,
                inputs=[
                    player_name, player_gender,
                    char_name, char_age, char_gender,
                    appearance, personality, speech_style,
                    p_val, a_val, d_val, i_val, t_val, dep_val,
                    initial_context, initial_background
                ],
                outputs=[
                    setup_status, tabs,
                    chatbot, gr.Textbox(visible=False), stats_display, image_display,
                    gr.Textbox(visible=False), thought_display, action_display, stats_chart,
                    submit_btn, user_input
                ]
            )
            
            # tabs ì»´í¬ë„ŒíŠ¸ì˜ change ì´ë²¤íŠ¸ ì—°ê²° (íƒ­ ì „í™˜ ì‹œ UI í™œì„±í™”)
            # íƒ­ì´ ë³€ê²½ë  ë•Œë§ˆë‹¤ UI ìƒíƒœ í™•ì¸
            tabs.change(
                enable_chat_ui,
                inputs=[],
                outputs=[submit_btn, user_input]
            )
            
            # ì„¤ì • ë¡œë“œ ì‹œ UI ì—…ë°ì´íŠ¸
            demo.load(
                enable_chat_ui,
                inputs=[],
                outputs=[submit_btn, user_input]
            )
            
            # Footer ì¶”ê°€
            gr.Markdown(
                f"""
                <div style="text-align: center; margin-top: 20px; padding: 10px; color: #666;">
                    â¤ï¸ <a href="https://zeniji.love" target="_blank" style="color: #666; text-decoration: none;">zeniji.love</a><br>
                    ğŸ’¬ <a href="https://arca.live/b/zeniji" target="_blank" style="color: #666; text-decoration: none;">Zeniji Channel on Arcalive(KR)</a><br>
                    â˜• <a href="https://buymeacoffee.com/zeniji" target="_blank" style="color: #666; text-decoration: none;">Buy Me a Coffee</a><br>
                    <span style="font-size: 0.85em; opacity: 0.7;">Version {config.VERSION}</span>
                </div>
                """
            )
        
        return demo

